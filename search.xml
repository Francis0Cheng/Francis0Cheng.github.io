<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tensorflow模型保存与恢复]]></title>
    <url>%2F2019%2F04%2F01%2Ftensorflow-model-save-and-restore%2F</url>
    <content type="text"><![CDATA[1. 什么是TensorFlow模型？训练了一个神经网络之后，我们希望保存它以便将来使用。那么什么是TensorFlow模型? Tensorflow模型主要包含我们所培训的网络参数的网络设计或图形和值。因此，Tensorflow模型有两个主要的文件: a) Meta graph： 这是一个协议缓冲区，它保存了完整的Tensorflow图形;即所有变量、操作、集合等。该文件以.meta作为扩展名。 b) Checkpoint file： ​ 这是一个二进制文件，它包含了所有的权重、偏差、梯度和其他所有变量的值。这个文件有一个扩展名.ckpt。然而，Tensorflow从0.11版本中改变了这一点。现在，我们有两个文件，而不是单个.ckpt文件: model.ckpt.data-00000-of-00001 model.ckpt.meta .data文件是包含我们训练变量的文件，我们待会将会使用它。 与此同时，Tensorflow也有一个名为checkpoint的文件，它只保存的最新保存的checkpoint文件的记录。 因此，为了总结，对于大于0.10的版本，Tensorflow模型如下: 在0.11之前的Tensorflow模型仅包含三个文件: inception_v1.meta inception_v1.ckpt checkpoint 之后的Tensorflow模型包含多了一个文件 model.ckpt.data-00000-of-00001 现在我们已经知道了Tensorflow模型的样子，接下来我们来看看TensorFlow是如何保存模型的。 2. 保存TensorFlow模型比方说，你正在训练一个卷积神经网络来进行图像分类。作为一种标准的练习，你要时刻关注损失和准确率。一旦看到网络已经收敛，我们可以暂停模型的训练。在完成培训之后，我们希望将所有的变量和网络结构保存到一个文件中，以便将来使用。因此，在Tensorflow中，我们希望保存所有参数的图和值，我们将创建一个tf.train.Saver()类的实例。 1saver = tf.train.Saver() 请记住，Tensorflow变量仅在会话中存在。因此，您必须在一个会话中保存模型，调用您刚刚创建的save方法。 1saver.save(sess, 'my-test-model') 这里，sess是会话对象，而’my-test-model’是保存的模型的名称。让我们来看一个完整的例子: 1234567891011121314import tensorflow as tfw1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')saver = tf.train.Saver()sess = tf.Session()sess.run(tf.global_variables_initializer())saver.save(sess, 'my_test_model')# This will save following files in Tensorflow v &gt;= 0.11# my_test_model.data-00000-of-00001# my_test_model.index# my_test_model.meta# checkpoint 如果我们在1000次迭代之后保存模型，我们将通过global_step来调用save: 1saver.save(sess, 'my_test_model',global_step=1000) 这将会将’-1000’追加到模型名称，并创建以下文件: my_test_model-1000.index my_test_model-1000.meta my_test_model-1000.data-00000-of-00001 checkpoint 比方说，在训练时，我们在每次1000次迭代后都保存模型，所以.meta文件是第一次创建的(在第1000次迭代中)，我们不需要每次都重新创建.meta文件(我们在2000，3000次没有保存.meta文件)。我们仅为进一步的迭代保存模型，因为图不会改变。因此，当我们不想保存meta-graph时，我们用这个: 1saver.save(sess, 'my-model', global_step=step,write_meta_graph=False) 如果你希望仅保留4个最新的模型，并且希望在训练过程中每两个小时后保存一个模型，那么你可以使用max_to_keep和keep_checkpoint_every_n_hours这样做。 12#saves a model every 2 hours and maximum 4 latest models are saved.saver = tf.train.Saver(max_to_keep=4, keep_checkpoint_every_n_hours=2) 注意，如果我们在tf.train.Saver()中没有指定任何东西，它将保存所有的变量。如果，我们不想保存所有的变量，而只是一些变量。我们可以指定要保存的变量/集合。在创建tf.train。保护程序实例，我们将它传递给我们想要保存的变量的列表或字典。让我们来看一个例子: 1234567import tensorflow as tfw1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')saver = tf.train.Saver([w1,w2])sess = tf.Session()sess.run(tf.global_variables_initializer())saver.save(sess, 'my_test_model',global_step=1000) 这可以用于在需要时保存特定的Tensorflow图。 3. 导入训练好的模型如果你想用别人预先训练好的模型来进行微调，你需要做以下两件事: a)创建网络 你可以通过编写python代码创建网络，以手工创建每一层，并将其作为原始模型。但是，如果你考虑一下，我们已经在.meta文件中保存了这个网络，我们可以使用tf.train.import()函数来重新创建这个网络： 1saver = tf.train.import_meta_graph('my_test_model-1000.meta') 记住，import_meta_graph将在.meta文件中定义的网络附加到当前图。因此，这将为你创建图形/网络，但是我们仍然需要加载我们在这张图上训练过的参数的值。 b)载入参数 我们可以通过调用这个保护程序的实例来恢复网络的参数，它是tf.train.Saver()类的一个实例。 123with tf.Session() as sess:new_saver = tf.train.import_meta_graph('my_test_model-1000.meta')new_saver.restore(sess, tf.train.latest_checkpoint('./')) 在此之后，像w1和w2这样的张量的值已经恢复并且可以被访问: 直接用sess run 张量的名字， 可以通过张量的name属性获得名字比如w1.name 12345with tf.Session() as sess: saver = tf.train.import_meta_graph('my-model-1000.meta') saver.restore(sess,tf.train.latest_checkpoint('./')) print(sess.run('w1:0'))##Model has been restored. Above statement will print the saved value of w1 因此，现在你已经了解了如何为Tensorflow模型保存和导入工作。在下一节中，我描述了上面的实际使用，以加载任何预先训练过的模型。 4.使用导入的模型现在你已经了解了如何保存和恢复Tensorflow模型，让我们开发一个实用的例子来恢复任何预先训练的模型，并·使用它进行预测、微调或进一步训练。当您使用Tensorflow时，你将定义一个图，该图是feed examples(训练数据)和一些超参数(如学习速率、迭代次数等)，它是一个标准的过程，我们可以使用占位符来存放所有的训练数据和超参数。接下来，让我们使用占位符构建一个小网络并保存它。注意，当网络被保存时，占位符的值不会被保存。 12345678910111213141516171819import tensorflow as tf#Prepare to feed input, i.e. feed_dict and placeholdersw1 = tf.placeholder("float", name="w1")w2 = tf.placeholder("float", name="w2")b1= tf.Variable(2.0,name="bias")feed_dict =&#123;w1:4,w2:8&#125;#Define a test operation that we will restorew3 = tf.add(w1,w2)w4 = tf.multiply(w3,b1,name="op_to_restore")sess = tf.Session()sess.run(tf.global_variables_initializer())#Create a saver object which will save all the variablessaver = tf.train.Saver()#Run the operation by feeding inputprint sess.run(w4,feed_dict)#Prints 24 which is sum of (w1+w2)*b1 #Now, save the graphsaver.save(sess, 'my_test_model',global_step=1000) 现在，当我们想要恢复它时，我们不仅要恢复图和权重，还要准备一个新的feed_dict，它将把新的训练数据输入到网络中。我们可以通过graph.get_tensor_by_name()方法来引用这些保存的操作和占位符变量。 1234#How to access saved variable/Tensor/placeholders w1 = graph.get_tensor_by_name("w1:0")## How to access saved operationop_to_restore = graph.get_tensor_by_name("op_to_restore:0") 如果我们只是想用不同的数据运行相同的网络，您可以简单地通过feed_dict将新数据传递给网络。 1234567891011121314151617import tensorflow as tfsess=tf.Session() #First let's load meta graph and restore weightssaver = tf.train.import_meta_graph('my_test_model-1000.meta')saver.restore(sess,tf.train.latest_checkpoint('./'))# Now, let's access and create placeholders variables and# create feed-dict to feed new datagraph = tf.get_default_graph()w1 = graph.get_tensor_by_name("w1:0")w2 = graph.get_tensor_by_name("w2:0")feed_dict =&#123;w1:13.0,w2:17.0&#125;#Now, access the op that you want to run. op_to_restore = graph.get_tensor_by_name("op_to_restore:0")print sess.run(op_to_restore,feed_dict)#This will print 60 which is calculated #using new values of w1 and w2 and saved value of b1. 如果你希望通过添加更多的层数并对其进行训练，从而向图中添加更多的操作，可以这样做 123456789101112131415161718import tensorflow as tfsess=tf.Session() #First let's load meta graph and restore weightssaver = tf.train.import_meta_graph('my_test_model-1000.meta')saver.restore(sess,tf.train.latest_checkpoint('./'))# Now, let's access and create placeholders variables and# create feed-dict to feed new datagraph = tf.get_default_graph()w1 = graph.get_tensor_by_name("w1:0")w2 = graph.get_tensor_by_name("w2:0")feed_dict =&#123;w1:13.0,w2:17.0&#125;#Now, access the op that you want to run. op_to_restore = graph.get_tensor_by_name("op_to_restore:0")#Add more to the current graphadd_on_op = tf.multiply(op_to_restore,2)print sess.run(add_on_op,feed_dict)#This will print 120. 但是，你是否可以在之前图的结构上构建新的网络?当然，您可以通过graph.get_tensor_by_name()方法访问适当的操作，并在此基础上构建图。这是一个真实的例子。在这里，我们使用元图加载一个vgg预训练的网络，并在最后一层中将输出的数量更改为2，以便对新数据进行微调。 123456789101112131415saver = tf.train.import_meta_graph('vgg.meta')# Access the graphgraph = tf.get_default_graph()## Prepare the feed_dict for feeding data for fine-tuning #Access the appropriate output for fine-tuningfc7= graph.get_tensor_by_name('fc7:0')#use this if you only want to change gradients of the last layerfc7 = tf.stop_gradient(fc7) # It's an identity functionfc7_shape= fc7.get_shape().as_list()new_outputs=2weights = tf.Variable(tf.truncated_normal([fc7_shape[3], num_outputs], stddev=0.05))biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))output = tf.matmul(fc7, weights) + biasespred = tf.nn.softmax(output)# Now, you run this with fine-tuning data in sess.run() 希望这能让你清楚地了解如何保存和恢复Tensorflow模型。 原文链接：http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab数据处理]]></title>
    <url>%2F2019%2F03%2F31%2Fmatlab-data-process%2F</url>
    <content type="text"><![CDATA[Matmab数据处理Matlab生成正态分布的数据需要两个指标， 一个是原有数据的平均数（&mu;）和标准差（&sigma;） 平均数计算函数mean(数据， 维度) 标准差计算函数std(数据， w， 维度) ​ 第二个参数w决定了用哪一个标准差函数，如果取0，则代表除以N-1，如果是1代表的是除以N。 如数据为 data = [1 2 3]， 那么 std(data, 0) 计算的结果就是根号sqrt((1+1)/(3-1))=1 , std(data, 1) 计算的结果就是sqrt((1+1)/3)=0.81645了 最后得到正态分布的公式是 标准差* randn(NUM, 1)+平均数 1new_data(i, :) = std_data(i)*randn(NUM, 1) +mu_data(i); 其中NUM是生成多少个数据, 可以用hist()函数画出生成数据的直方图看看是不是正态分布的 标准化函数 标准化 zscore(data, 0, 1) 1代表列]]></content>
  </entry>
  <entry>
    <title><![CDATA[css选择器]]></title>
    <url>%2F2019%2F03%2F29%2Fcss-selector%2F</url>
    <content type="text"><![CDATA[一个有趣的css选择器小游戏: http://flukeout.github.io/ Adjacent Sibling Selector（兄弟选择器）Select an element that directly follows another elementA + BThis selects all B elements that directly follow A. Elements that follow one another are called siblings. They’re on the same level, or depth. In the HTML markup for this level, elements that have the same indentation are siblings. Examplesp + .intro selects every element with class=”intro” that directly follows a p div + a selects every a element that directly follows a div General Sibling Selector（可以选择多个兄弟）Select elements that follows another elementA ~ BYou can select all siblings of an element that follow it. This is like the Adjacent Selector (A + B) except it gets all of the following elements instead of one. ExamplesA ~ B selects all B that follow a A Child Selector（直系孩子）Select direct children of an elementA &gt; BYou can select elements that are direct children of other elements. A child element is any element that is nested directly in another element. Elements that are nested deeper than that are called descendant elements. ExamplesA &gt; B selects all B that are a direct children A First Child Pseudo-selector（第一个儿子）Select a first child element inside of another element:first-childYou can select the first child element. A child element is any element that is directly nested in another element. You can combine this pseudo-selector with other selectors. Examples:first-child selects all first child elements. p:first-child selects all first child pelements. div p:first-child selects all first child pelements that are in a div. Only Child Pseudo-selector（只有一个儿子的）Select an element that are the only element inside of another one.:only-childYou can select any element that is the only element inside of another one. Examplesspan:only-child selects the span elements that are the only child of some other element. ul li:only-child selects the only li element that are in a ul. Last Child Pseudo-selectorSelect the last element inside of another element:last-childYou can use this selector to select an element that is the last child element inside of another element. Pro Tip → In cases where there is only one element, that element counts as the first-child, only-child and last-child! Examples:last-child selects all last-child elements. span:last-child selects all last-child spanelements. ul li:last-child selects the last lielements inside of any ul. Nth Child Pseudo-selectorSelect an element by its order in another element#+# :nth-child(A) Selects the nth (Ex: 1st, 3rd, 12th etc.) child element in another element. Examples:nth-child(8) selects every element that is the 8th child of another element. div p:nth-child(2) selects the second p in every div Nth Last Child SelectorSelect an element by its order in another element, counting from the back:nth-last-child(A)Selects the children from the bottom of the parent. This is like nth-child, but counting from the back! Examples:nth-last-child(2) selects all second-to-last child elements. First of Type SelectorSelect the first element of a specific type#+# :first-of-type Selects the first element of that type within another element. Examplesspan:first-of-type selects the first span in any element. Nth of Type Selector#+# :nth-of-type(A) Selects a specific element based on its type and order in another element - or even or odd instances of that element. Examplesdiv:nth-of-type(2) selects the second instance of a div. .example:nth-of-type(odd) selects all odd instances of a the example class. Nth-of-type Selector with Formula（带有方程的）:nth-of-type(An+B)The nth-of-type formula selects every nth element, starting the count at a specific instance of that element. Examplesspan:nth-of-type(6n+2) selects every 6th instance of a span, starting from (and including) the second instance. Only of Type SelectorSelect elements that are the only ones of their type within of their parent element#+# :only-of-type Selects the only element of its type within another element. Examplesp span:only-of-type selects a span within any p if it is the only span in there. Last of Type SelectorSelect the last element of a specific type:last-of-typeSelects each last element of that type within another element. Remember type refers the kind of tag, so p and span are different types. I wonder if this is how the last dinosaur was selected before it went extinct. Examplesdiv:last-of-type selects the last div in every element. p span:last-of-type selects the last span in every p. Empty SelectorSelect elements that don’t have children:emptySelects elements that don’t have any other elements inside of them. Examplesdiv:empty selects all empty div elements. Negation Pseudo-classSelect all elements that don’t match the negation selector:not(X)You can use this to select all elements that do not match selector “X”. Examples:not(#fancy) selects all elements that do not have id=”fancy”. div:not(:first-child) selects every div that is not a first child. :not(.big, .medium) selects all elements that do not have class=”big” or class=”medium”. Attribute SelectorSelect all elements that have a specific attribute[attribute]Attributes appear inside the opening tag of an element, like this: span attribute=”value”. An attribute does not always have a value, it can be blank! Examplesa[href] selects all a elements that have a href=”anything” attribute. [type] selects all elements that have a type=”anything”. attribute Attribute Value SelectorSelect all elements that have a specific attribute value[attribute=”value”]Attribute selectors are case sensitive, each character must match exactly. Examplesinput[type=”checkbox”] selects all checkbox input elements. Attribute Starts With SelectorSelect all elements with an attribute value that starts with specific characters[attribute^=”value”]Examples.toy[category^=”Swim”] selects elements with class toy and either category=”Swimwear or category=”Swimming”. Attribute Ends With SelectorSelect all elements with an attribute value that ends with specific characters[attribute$=”value”]Examplesimg[src$=”.jpg”] selects all images display a .jpg image. Attribute Wildcard SelectorSelect all elements with an attribute value that contains specific characters anywhere[attribute*=”value”]A useful selector if you can identify a common pattern in things like class, href or srcattributes. Examplesimg[src*=”/thumbnails/“] selects all image elements that show images from the “thumbnails” folder. [class*=”heading”] selects all elements with “heading” in their class, like class=”main-heading”and class=”sub-heading”]]></content>
      <categories>
        <category>css</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Just For Fun (Linux Torvalds自传)英文版]]></title>
    <url>%2F2019%2F03%2F28%2Fjust-for-fun%2F</url>
    <content type="text"><![CDATA[《Just for Fun》是托瓦兹唯一的一本自传，全书充斥着托瓦兹独特的幽默感，以及「托瓦兹式」的思考逻辑与对话，让人不禁惊叹，一个不时置身于镁光灯下与金钱洪流中的平凡名人，为何还能如此单纯率真。经由记者大卫??戴蒙(David Diamond)的促成，托瓦兹的童年、生活、想法与经历，一一生动地展现在读者面前，不仅记录了Linux出生的过程与其后所造成的轩然大波，也详实刻画出托瓦兹本人对于他这项「意外的革命」的低调态度，让人在参与托瓦兹成长、成名的历程之际，不得不为他风趣乐观、自我解嘲却不自我贬抑的性格，鼓掌喝采；另一方面，戴蒙也由另一个不同的观点，穿插记载托瓦兹在他这个外人眼中的形象，以及两人互动对话的过程。 坑先占着， 还没看完]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人工智能浅谈（朱松纯）]]></title>
    <url>%2F2019%2F03%2F28%2Fren-gong-zhi-neng-qian-tan%2F</url>
    <content type="text"><![CDATA[pdf连接：www.stat.ucla.edu/~sczhu/Blog_articles/浅谈人工智能.pdf 人工智能浅谈（朱松纯）后感我是由袁老师的视频知道并开始看这本书的：https://www.bilibili.com/video/av32104086 摘录一些语句 我的看法很简单：大多数写报道和搞炒作宣传的人，基本不懂人工智能。这就像年轻人玩的传话游戏，扭曲的信息在多次传导过程中]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[shortcuts]]></title>
    <url>%2F2019%2F03%2F28%2Fshortcuts%2F</url>
    <content type="text"><![CDATA[itelliJ 缩写 补全内容 psvm public static void main(String[] args){} sout System.out.println(); (在 Kotlin 中是 println()) souf System.out.printf(); serr System.err.println(); psf public static final psfi public static final int psfs public static final String toast Toast.makeText(this, “”, Toast.LENGTH_SHORT).show(); (仅限 Android)]]></content>
      <tags>
        <tag>shortcuts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中文件夹和文件的操作]]></title>
    <url>%2F2019%2F03%2F20%2Flinux-operation%2F</url>
    <content type="text"><![CDATA[Linux中文件夹和文件的操作移动文件使用mv命令 1mv /home/jack/testfile /home/jack/testfile2 如果你在/home/jack文件夹中就可以直接 1mv testfile testfile2 如果只想移动文件 1mv /home/jack/testfile /home/jack/Documents/ 如果想批量移动相似的文件类型比如说你的Downloads文件夹中包含了很多mp3文件，你想要将他们都移动到Music文件夹中 1mv ~/Downloads/*.mp3 ~/Music/ 移动文件夹移动文件夹和移动文件是一样的 1mv /home/vivek/data/ /nas/home/vivek/archived/ 只需要加上slash就行了，表示这个文件夹 移动到一个不存在的文件夹目录下的新文件夹 1mkdir --parents ./some/path/; mv yourfile.txt $_ 杀掉某一个端口的程序 fuser 8080/tcp will print you PID of process bound on that port. fuser -k 8080/tcp will kill that process. More universal is use of lsof -i4 (or 6 for IPv6).]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tricks]]></title>
    <url>%2F2019%2F03%2F18%2Ftricks%2F</url>
    <content type="text"><![CDATA[解决opencv中读取中文路径的图片的问题123def cv_imread(file_path): cv_img = cv2.imdecode(np.fromfile(file_path,dtype=np.uint8),-1) return cv_img matlab 把数组中的NaN去除掉123a = [NaN 1 2 3 4];p = find(isnan(a))a(p) = []; mysql 创建数据库时指定utf-8编码创建数据库编码指定1CREATE DATABASE dbname DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 设置数据表编码123456CREATE TABLE &apos;author&apos; ( &apos;authorid&apos; char(20) NOT NULL, &apos;name&apos; char(20) NOT NULL, &apos;age&apos; char(20) NOT NULL, &apos;country&apos; char(20) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 AUTO_INCREMENT=1; Xshell 传输和接受文件首先需要安装 lrzsz 1apt-get install lrzsz 传输sz , s 应该是sent 接受rz , r 应该是 recieve Tensorflow one-hot编码转换函数这个函数会将numpy标签矩阵转化为one-hot编码矩阵， 要注意转置的问题 12def convert_to_one_hot(y, C): return np.eye(C)[y.reshape(-1)].T Windows下Python中文件路径字符串改成能用的1s.replace('\\', '\\\\')]]></content>
      <categories>
        <category>Tricks</category>
      </categories>
      <tags>
        <tag>Tricks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim]]></title>
    <url>%2F2019%2F03%2F17%2Fvim%2F</url>
    <content type="text"><![CDATA[VIM学习清空一行内容而不是删除一行0D]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdspider]]></title>
    <url>%2F2019%2F03%2F07%2Fjdspider%2F</url>
    <content type="text"><![CDATA[先占个位置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172import requestsfrom lxml import etreeimport csvfrom bs4 import BeautifulSoupfrom selenium import webdriverimport redef getHTMLText(goods): url = 'https://search.jd.com/Search?keyword='+ goods+ '&amp;enc=utf-8' head=&#123;'authority': 'search.jd.com', 'method': 'GET', 'path': '/s_new.php?keyword=%E6%89%8B%E6%9C%BA&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=%E6%89%8B%E6%9C%BA&amp;cid2=653&amp;cid3=655&amp;page=4&amp;s=84&amp;scrolling=y&amp;log_id=1529828108.22071&amp;tpl=3_M&amp;show_items=7651927,7367120,7056868,7419252,6001239,5934182,4554969,3893501,7421462,6577495,26480543553,7345757,4483120,6176077,6932795,7336429,5963066,5283387,25722468892,7425622,4768461', 'scheme': 'https', 'referer': 'https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=%E6%89%8B%E6%9C%BA&amp;cid2=653&amp;cid3=655&amp;page=3&amp;s=58&amp;click=0', 'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36', 'x-requested-with': 'XMLHttpRequest', 'Cookie':'qrsc=3; pinId=RAGa4xMoVrs; xtest=1210.cf6b6759; ipLocation=%u5E7F%u4E1C; _jrda=5; TrackID=1aUdbc9HHS2MdEzabuYEyED1iDJaLWwBAfGBfyIHJZCLWKfWaB_KHKIMX9Vj9_2wUakxuSLAO9AFtB2U0SsAD-mXIh5rIfuDiSHSNhZcsJvg; shshshfpa=17943c91-d534-104f-a035-6e1719740bb6-1525571955; shshshfpb=2f200f7c5265e4af999b95b20d90e6618559f7251020a80ea1aee61500; cn=0; 3AB9D23F7A4B3C9B=QFOFIDQSIC7TZDQ7U4RPNYNFQN7S26SFCQQGTC3YU5UZQJZUBNPEXMX7O3R7SIRBTTJ72AXC4S3IJ46ESBLTNHD37U; ipLoc-djd=19-1607-3638-3638.608841570; __jdu=930036140; user-key=31a7628c-a9b2-44b0-8147-f10a9e597d6f; areaId=19; __jdv=122270672|direct|-|none|-|1529893590075; PCSYCityID=25; mt_xid=V2_52007VwsQU1xaVVoaSClUA2YLEAdbWk5YSk9MQAA0BBZOVQ0ADwNLGlUAZwQXVQpaAlkvShhcDHsCFU5eXENaGkIZWg5nAyJQbVhiWR9BGlUNZwoWYl1dVF0%3D; __jdc=122270672; shshshfp=72ec41b59960ea9a26956307465948f6; rkv=V0700; __jda=122270672.930036140.-.1529979524.1529984840.85; __jdb=122270672.1.930036140|85.1529984840; shshshsID=f797fbad20f4e576e9c30d1c381ecbb1_1_1529984840145' &#125; try: r =requests.get(url,headers = head ,timeout = 30) r.raise_for_status() r.encoding = r.apparent_encoding return r.text except: return ""def searchGoods(brand): soup = BeautifulSoup(brand,'html.parser') data1 = soup.find('ul',&#123;"class":"J_valueList v-fixed"&#125;) datali =data1.find_all('li') Goods_href=[] Goods_name=[] for li in datali: Goods_name.append(li.a.attrs['title']) print(li.a.attrs['title']) Goods_href.append(li.a.attrs['href']) count = 0 for j in range(len(Goods_href)): print("&lt;&lt;&lt;&#123;&#125;.".format(count+1),"品牌 :"+Goods_name[j]) count = count+1 judge = 1 while(judge): Goods_num = input("请输入品牌对应序号:") if Goods_num.isdigit(): judge = 0 else: print("您的输入有误，请输入数字：") continue a = int(Goods_num) if a&gt;count: print("输入序号过大，请重新输入：") judge = 1 elif a&lt;1: print("输入序号过小，请重新输入：") judge = 1 print("选择的品牌是： "+Goods_name[int(Goods_num)-1]) brand_url = "https://search.jd.com/"+Goods_href[int(Goods_num)-1] return brand_urldef orderBy(brand_url): judge = 1 while(judge): kind = input("按照：综合 / 销量 / 评论数 / 新品 / 价格 进行排序（默认综合）") strinfo =re.compile('uc=0#J_searchWrap')#在对网页的url进行分析的时候发现 uc=0#J_searchWrap可以删减，如果点击不同的话对应的知识psort的值不同 if kind == '综合': judge = 0 return 0 if kind == '销量': b = strinfo.sub('psort=3',brand_url) judge = 0 elif kind =='评论数': b = strinfo.sub('psort=4',brand_url) judge = 0 elif kind =='新品': b = strinfo.sub('psort=5',brand_url) judge = 0 elif kind =='价格': b = strinfo.sub('psort=2',brand_url) judge = 0 else : print("输入有误，请重新输入：") return bdef focus_good(new_brand_url): head=&#123;'authority': 'search.jd.com', 'method': 'GET', 'path': '/s_new.php?keyword=%E6%89%8B%E6%9C%BA&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=%E6%89%8B%E6%9C%BA&amp;cid2=653&amp;cid3=655&amp;page=4&amp;s=84&amp;scrolling=y&amp;log_id=1529828108.22071&amp;tpl=3_M&amp;show_items=7651927,7367120,7056868,7419252,6001239,5934182,4554969,3893501,7421462,6577495,26480543553,7345757,4483120,6176077,6932795,7336429,5963066,5283387,25722468892,7425622,4768461', 'scheme': 'https', 'referer': 'https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=%E6%89%8B%E6%9C%BA&amp;cid2=653&amp;cid3=655&amp;page=3&amp;s=58&amp;click=0', 'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36', 'x-requested-with': 'XMLHttpRequest', 'Cookie':'qrsc=3; pinId=RAGa4xMoVrs; xtest=1210.cf6b6759; ipLocation=%u5E7F%u4E1C; _jrda=5; TrackID=1aUdbc9HHS2MdEzabuYEyED1iDJaLWwBAfGBfyIHJZCLWKfWaB_KHKIMX9Vj9_2wUakxuSLAO9AFtB2U0SsAD-mXIh5rIfuDiSHSNhZcsJvg; shshshfpa=17943c91-d534-104f-a035-6e1719740bb6-1525571955; shshshfpb=2f200f7c5265e4af999b95b20d90e6618559f7251020a80ea1aee61500; cn=0; 3AB9D23F7A4B3C9B=QFOFIDQSIC7TZDQ7U4RPNYNFQN7S26SFCQQGTC3YU5UZQJZUBNPEXMX7O3R7SIRBTTJ72AXC4S3IJ46ESBLTNHD37U; ipLoc-djd=19-1607-3638-3638.608841570; __jdu=930036140; user-key=31a7628c-a9b2-44b0-8147-f10a9e597d6f; areaId=19; __jdv=122270672|direct|-|none|-|1529893590075; PCSYCityID=25; mt_xid=V2_52007VwsQU1xaVVoaSClUA2YLEAdbWk5YSk9MQAA0BBZOVQ0ADwNLGlUAZwQXVQpaAlkvShhcDHsCFU5eXENaGkIZWg5nAyJQbVhiWR9BGlUNZwoWYl1dVF0%3D; __jdc=122270672; shshshfp=72ec41b59960ea9a26956307465948f6; rkv=V0700; __jda=122270672.930036140.-.1529979524.1529984840.85; __jdb=122270672.1.930036140|85.1529984840; shshshsID=f797fbad20f4e576e9c30d1c381ecbb1_1_1529984840145' &#125; r = requests.get(new_brand_url,headers = head) r.encoding = 'utf-8' html1 = etree.HTML(r.text) datas = html1.xpath('//li[contains(@class,"gl-item")]') count = 1 goods_href =[] for data in datas: p_price = data.xpath('div/div[@class="p-price"]/strong/i/text()') # p_comment = data.xpath('div/div[5]/strong/a/text()') p_name = data.xpath('div/div[@class="p-name p-name-type-2"]/a/em') p_href = data.xpath('div/div[@class="p-name p-name-type-2"]/a/@href') print(count,[p_name[0].xpath('string(.)'),p_price[0]]) goods_href.append(p_href) count = count+1 judge = 1 while(judge): focus_num = input("您关注的商品序号是:") if focus_num.isdigit(): judge = 0 else: print("您的输入有误，请输入数字：") continue a = int(focus_num) if a&gt;count-1: print("输入序号过大，请重新输入：") judge = 1 elif a&lt;1: print("输入序号过小，请重新输入：") judge = 1 focus_good_url = goods_href[int(focus_num)-1] # print(focus_good_url) return focus_good_urldef open_Firefox(num): #location = 'D:/firefox-48.0b9.win64.sdk/firefox-sdk/bin/firefox.exe' driver = webdriver.Chrome() driver.get(num) focus_url = driver.current_url focus_title = driver.title[:-16] YesorNo3 = input("是否将此商品加入关注列表？(yes or no)") if YesorNo3 == 'yes': print("商品已成功加入关注列表") with open('JD_goods.csv', 'a', newline="", encoding='utf-8') as f: write1 = csv.writer(f) write1.writerow([focus_title]) write1.writerow([focus_url]) write1.writerow(["---------------------------"])if __name__=='__main__': judge = 1 while(judge): YesorNo = input("是否需要打开关注商品信息：(yes or no)") if YesorNo == 'yes' or YesorNo == 'YES': with open('JD_goods.csv','r',encoding='utf-8') as cv: cv_read = cv.read() print(cv_read) judge = 0 elif YesorNo == 'no' or YesorNo == 'NO': judge = 0 else: print("输入有误，请重新输入：") goods_name =input("请输入需要查询的商品种类：") data = getHTMLText(goods_name) YesorNo2 = input("是否需要根据商品品牌进行排列：(yes or no)") if YesorNo2 == 'yes': brand_url = searchGoods(data) else : brand_url = searchGoods(data) new_brand_url = orderBy(brand_url) focus_good_url = focus_good(new_brand_url) str1 = str(focus_good_url) new_url = "https:"+str1[2:-2] # print(new_url) open_Firefox(new_url)]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow中的几种交叉熵]]></title>
    <url>%2F2019%2F03%2F07%2FTensorFlow%E4%B8%AD%E7%9A%84%E5%87%A0%E7%A7%8D%E4%BA%A4%E5%8F%89%E7%86%B5%2F</url>
    <content type="text"><![CDATA[TensorFlow中的几种交叉熵Logit函数在线性回归中，，是用直线去拟合数据，实现最小二乘意义下的最小预测误差。 在逻辑回归中：可以看作是用直线去拟合Logit函数，通过极大似然估计出参数，使得在该参数下，能以最大概率生成当前的样本。 logits函数是一种将取值范围在[0,1]内的概率映射到实数域[-inf,inf]的函数，如果p=0.5，函数值为0；p&lt;0.5，函数值为负；p&gt;0.5，函数值为正。 相对地，softmax和sigmoid则都是将[-inf,inf]映射到[0,1]的函数。 在tensorflow里的”logits”指的其实是，该方法是在logit数值上使用softmax或者sigmoid来进行normalization的，也暗示用户不要将网络输出进行sigmoid或者softmax，这些过程可以在函数内部更高效地计算。 独立和互斥有事件A和B 独立：P(AnB) = P(A) * P(B) 互斥：P(AUB) = P(A) + P(B), P(AnB) = 0 1、tf.nn.sigmoid_cross_entropy_with_logits123456sigmoid_cross_entropy_with_logits( _sentinel=None, labels=None, logits=None, name=None) 计算网络输出logits和标签labels的sigmoid cross entropy loss，衡量独立不互斥离散分类任务的误差，说独立不互斥离散分类任务是因为，在这些任务中类与类之间是独立但是不互斥的，拿多分类任务中的多目标检测来举例子，一张图中可以有各种instance，比如有一只狗和一只猫。对于一个总共有五类的多目标检测任务，假如网络的输出层有5个节点，label的形式是[1,1,0,0,1]这种，1表示该图片有某种instance，0表示没有。那么，每个instance在这张图中有没有这显然是独立事件，但是多个instance可以存在一张图中，这就说明事件们并不是互斥的。所以我们可以直接将网络的输出用作该方法的logits输入，从而进行输出与label的cross entropy loss。 更加直白的来说，这种网络的输入不需要进行one hot处理，网络输出即是函数logits参数的输入。 剖开函数内部，因为labels和logits的形状都是[batch_size, num_classes]，那么如何计算他们的交叉熵呢，毕竟它们都不是有效的概率分布（一个batch内输出结果经过sigmoid后和不为1）。其实loss的计算是element-wise的，方法返回的loss的形状和labels是相同的，也是[batch_size, num_classes]，再调用reduce_mean方法计算batch内的平均loss。所以这里的cross entropy其实是一种class-wise的cross entropy，每一个class是否存在都是一个事件，对每一个事件都求cross entropy loss，再对所有的求平均，作为最终的loss。 2、tf.nn.softmax_cross_entropy_with_logits1234567softmax_cross_entropy_with_logits( _sentinel=None, labels=None, logits=None, dim=-1, name=None) 计算网络输出logits和标签labels的softmax cross entropy loss，衡量独立互斥离散分类任务的误差，说独立互斥离散分类任务是因为，在这些任务中类与类之间是独立而且互斥的，比如VOC classification、Imagenet、CIFAR-10甚至MNIST，这些都是多分类任务，但是一张图就对应着一个类，class在图片中是否存在是独立的，并且一张图中只能有一个class，所以是独立且互斥事件。 该函数要求每一个label都是一个有效的概率分布，对于Imagenet中的ILSVRC2012这种任务，那么label应该就对应一个one hot编码，ILSVRC2012提供的数据集中一共有1000个类，那么label就应该是一个1x1000的vector，形式为[0,0,…,1,0,….0]，1000个元素中有且只有一个元素是1，其余都是0。 这样要求的原因很简单，因为网络的输出要进行softmax，得到的就是一个有效的概率分布，这里不同与sigmoid，因为sigmoid并没有保证网络所有的输出经过sigmoid后和为1，不是一个有效的概率分布。 有了labels和softmax后的logits，就可以计算交叉熵损失了，最后得到的是形状为[batch_size, 1]的loss。 3、tf.nn.sparse_softmax_cross_entropy_with_logits123456sparse_softmax_cross_entropy_with_logits( _sentinel=None, labels=None, logits=None, name=None) 这个版本是tf.nn.softmax_cross_entropy_with_logits的易用版本，这个版本的logits的形状依然是[batch_size, num_classes]，但是labels的形状是[batch_size, 1]，每个label的取值是从[0, num_classes)的离散值，这也更加符合我们的使用习惯，是哪一类就标哪个类对应的label。 如果已经对label进行了one hot编码，则可以直接使用tf.nn.softmax_cross_entropy_with_logits。 4、总结：到底是用sigmoid版本的cross entropy还是softmax版本的cross entropy主要取决于我们模型的目的，以及label的组织方式，这个需要大家在使用的时候去揣摩，到底使用哪一种loss比较合理。 在我最近训练的segmentation模型中，使用的就是sparse softmax cross entropy，使用的思路就是将输出的结果从NHWC（这里C=1，表示该pixel所属的class），进行一次reshape，形状变为[NHW, 1]，label也是如此，传入函数中进行计算，从而产生loss。从模型训练的结果来看，这种使用方法没有错误。]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy学习（二）命令行]]></title>
    <url>%2F2019%2F03%2F05%2Fscrapy2%2F</url>
    <content type="text"><![CDATA[简介Scrapy是通过Scrapy命令行工具进行控制的，包括创建新的项目，爬虫的启动，相关的设置，Scrapy提供了两种内置的命令，分别是全局命令和项目命令，顾名思义，全局命令就是在任意位置都可以执行的命令，而项目命令只有在你新创建了项目之后，在项目目录中才可以执行的命令。在这里，简单的介绍一些常用的命令。 全局命令 startproject语法: 1scrapy startproject &lt;project_name&gt; 这个命令是scrapy最为常用的命令之一，它将会在当前目录下创建一个名为 1&lt;project_name&gt; 的项目。 settings语法: 1scrapy settings [options] 该命令将会输出Scrapy默认设定，当然如果你在项目中运行这个命令将会输出项目的设定值。 runspider语法: 1scrapy runspider &lt;spider_file.py&gt; 在未创建项目的情况下，运行一个编写在Python文件中的spider。 shell语法: 1scrapy shell [url] 以给定的URL(如果给出)或者空(没有给出URL)启动Scrapy shell。 例如， 1scrapy shell http://www.baidu.com 将会打开百度URL， 并且启动交互式命令行，可以用来做一些测试。 fetch语法: 1scrapy fetch &lt;url&gt; 使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容送到标准输出。简单的来说，就是打印url的html代码。 view语法: 1scrapy view &lt;url&gt; 在你的默认浏览器中打开给定的URL，并以Scrapy spider获取到的形式展现。 有些时候spider获取到的页面和普通用户看到的并不相同，一些动态加载的内容是看不到的， 因此该命令可以用来检查spider所获取到的页面。 version语法: 1scrapy version [-v] 输出Scrapy版本。配合 -v 运行时，该命令同时输出Python, Twisted以及平台的信息。 项目命令 crawl语法: 1scrapy crawl &lt;spider_name&gt; 使用你项目中的spider进行爬取，即启动你的项目。这个命令将会经常用到，我们会在后面的内容中经常使用。 check语法: 1crapy check [-l] &lt;spider&gt; 运行contract检查，检查你项目中的错误之处。 list语法: 1scrapy list 列出当前项目中所有可用的spider。每行输出一个spider。 genspider语法: 1scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; 在当前项目中创建spider。该方法可以使用提前定义好的模板来生成spider。您也可以自己创建spider的源码文件。]]></content>
      <categories>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy学习（一）框架简介]]></title>
    <url>%2F2019%2F03%2F05%2Fscrapy1%2F</url>
    <content type="text"><![CDATA[概览Scrapy是一个Python编写的开源网络爬虫框架。它是一个被设计用于爬取网络数据、提取结构性数据的程序框架。[3]该框架主要由Scrapinghub 公司进行维护。scrapy官网给出的最新的架构图示。 基本组件 引擎（Engine） 引擎负责控制数据流在系统中所有组件中流动，并在相应动作发生时触发事件。 详细内容查看下面的数据流(Data Flow)部分。 调度器（Scheduler） 调度器从引擎接受request并将他们入队，以便之后引擎请求他们时提供给引擎。 下载器(Downloader) 下载器负责获取页面数据并提供给引擎，而后提供给spider。 爬虫（Spiders） Spider是Scrapy用户编写用于分析response并提取item(即获取到的item)或额外跟进的URL的类。 每个spider负责处理一个特定(或一些)网站。 管道（Item Pipeline） Item Pipeline负责处理被spider提取出来的item。典型的处理有清理、验证及持久化(例如存取到数据库中)。 下载器中间件（Downloader middlewares） 下载器中间件是在引擎及下载器之间的特定钩子(specific hook)，处理Downloader传递给引擎的response。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。 Spider中间件（Spider middlewares） Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。 数据流向Scrapy的数据流由执行引擎（Engine）控制，其基本过程如下： 1. 引擎从Spider中获取到初始Requests。 2. 引擎将该Requests放入调度器，并请求下一个要爬取的Requests。 3. 调度器返回下一个要爬取的Requests给引擎 4. 引擎将Requests通过下载器中间件转发给下载器(Downloader)。 5. 一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(返回(response)方向)发送给引擎。 6. 引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理。 7. Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎。 8. 引擎将(Spider返回的)爬取到的Item交给ItemPipeline处理，将(Spider返回的)Request交给调度器，并请求下一个Requests（如果存在的话）。 9. (从第一步)重复直到调度器中没有更多地Request。 总结 Scrapy的各个组件相互配合执行，有的组件负责任务的调度，有的组件负责任务的下载，有的组件负责数据的清洗保存，各组件分工明确。在组件之间存在middleware的中间件，其作用就是功能的拓展，当然还可以根据自身的需求自定义这些拓展功能，比如我们可以在Downloader middlewares里面实现User-Agent的切换，Proxy的切换等等。这些功能我们会在后续的学习中逐渐拓展。这里只需要大致的了解即可。]]></content>
      <categories>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[selenium详解]]></title>
    <url>%2F2019%2F03%2F03%2Fselenium%2F</url>
    <content type="text"><![CDATA[Selenium基本使用1234567891011121314151617181920212223242526272829from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Chrome()try: # 用chrome发出get请求 browser.get('https://www.baidu.com') # 找到id为kw的元素 input = browser.find_element_by_id('kw') # 输入Python input.send_keys('Python') # 调用ENTER input.send_keys(Keys.ENTER) # 等待 wait = WebDriverWait(browser, 10) # 直到ID为 content_left 元素出现 wait.until(EC.presence_of_element_located((By.ID, 'content_left'))) # URL地址 print(browser.current_url) # COOKIES print(browser.get_cookies()) # 源代码 print(browser.page_source)finally: # 关闭此浏览器 browser.close() 声明浏览器对象1234567from selenium import webdriverbrowser = webdriver.Chrome()browser = webdriver.Firefox()browser = webdriver.Edge()browser = webdriver.PhantomJS()browser = webdriver.Safari() 访问页面123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.taobao.com')print(browser.page_source)browser.close() 查找元素单个元素123456789from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.taobao.com')input_first = browser.find_element_by_id('q')input_second = browser.find_element_by_css_selector('#q')input_third = browser.find_element_by_xpath('//*[@id="q"]')print(input_first, input_second, input_third)browser.close() find_element_by_name find_element_by_xpath find_element_by_link_text find_element_by_partial_link_text find_element_by_tag_name find_element_by_class_name find_element_by_css_selector 12345678from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('https://www.taobao.com')input_first = browser.find_element(By.ID, 'q')print(input_first)browser.close() 通过browser.find_element加上from selenium.webdriver.common.by import By 多个元素1234567from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.taobao.com')lis = browser.find_elements_by_css_selector('.service-bd li')print(lis)browser.close() 把element加上复数形式 find_elements_by_name find_elements_by_xpath find_elements_by_link_text find_elements_by_partial_link_text find_elements_by_tag_name find_elements_by_class_name find_elements_by_css_selector 12345678from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('https://www.taobao.com')lis = browser.find_elements(By.CSS_SELECTOR, '.service-bd li')print(lis)browser.close() 元素交互操作对获取的元素调用交互方法 123456789101112from selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get('https://www.taobao.com')input = browser.find_element_by_id('q')input.send_keys('iPhone')time.sleep(1)input.clear()input.send_keys('iPad')button = browser.find_element_by_class_name('btn-search')button.click() 更多操作: http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement 交互动作123456789101112from selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')source = browser.find_element_by_css_selector('#draggable')target = browser.find_element_by_css_selector('#droppable')actions = ActionChains(browser)actions.drag_and_drop(source, target)actions.perform() 更多操作: http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains&gt; 执行JavaScript123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')browser.execute_script('window.scrollTo(0, document.body.scrollHeight)')browser.execute_script('alert("To Bottom")') 获取元素信息获取属性123456789from selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)logo = browser.find_element_by_id('zh-top-link-logo')print(logo)print(logo.get_attribute('class')) 获取文本值1234567from selenium import webdriverbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)input = browser.find_element_by_class_name('zu-top-add-question')print(input.text) 获取ID、位置、标签名、大小12345678910from selenium import webdriverbrowser = webdriver.Chrome()url = 'https://www.zhihu.com/explore'browser.get(url)input = browser.find_element_by_class_name('zu-top-add-question')print(input.id)print(input.location)print(input.tag_name)print(input.size) FrameFrame相当于一个网页，父Frame必须进入子Frame然后才能查找子Frame中的元素，子Frame中也不能获取父Frame中的元素 1234567891011121314151617181920import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')# swith_to.frame()传入frame的idsource = browser.find_element_by_css_selector('#draggable')print(source)try: logo = browser.find_element_by_class_name('logo')except NoSuchElementException: print('NO LOGO')browser.switch_to.parent_frame()#swith_to.parent_frame()切换到父Framelogo = browser.find_element_by_class_name('logo')print(logo)print(logo.text) 等待隐式等待当使用了隐式等待执行测试的时候，如果 WebDriver没有在 DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常, 换句话说，当查找元素或元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0 1234567from selenium import webdriverbrowser = webdriver.Chrome()browser.implicitly_wait(10)browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input) 显式等待1234567891011from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.get('https://www.taobao.com/')wait = WebDriverWait(browser, 10)input = wait.until(EC.presence_of_element_located((By.ID, 'q')))button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.btn-search')))print(input, button) title_is 标题是某内容 title_contains 标题包含某内容 presence_of_element_located 元素加载出，传入定位元组，如(By.ID, ‘p’) visibility_of_element_located 元素可见，传入定位元组 visibility_of 可见，传入元素对象 presence_of_all_elements_located 所有元素加载出 text_to_be_present_in_element 某个元素文本包含某文字 text_to_be_present_in_element_value 某个元素值包含某文字 frame_to_be_available_and_switch_to_it frame 加载并切换 invisibility_of_element_located 元素不可见 element_to_be_clickable 元素可点击 staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新 element_to_be_selected 元素可选择，传元素对象 element_located_to_be_selected 元素可选择，传入定位元组 element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回False element_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回False alert_is_present 是否出现Alert 前进后退1234567891011import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com/')browser.get('https://www.taobao.com/')browser.get('https://www.python.org/')browser.back()time.sleep(1)browser.forward()browser.close() Cookies设置登陆状态 123456789from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')print(browser.get_cookies())browser.add_cookie(&#123;'name': 'name', 'domain': 'www.zhihu.com', 'value': 'germey'&#125;)print(browser.get_cookies())browser.delete_all_cookies()print(browser.get_cookies()) 选项卡管理123456789101112import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.execute_script('window.open()')print(browser.window_handles)browser.switch_to_window(browser.window_handles[1])browser.get('https://www.taobao.com')time.sleep(1)browser.switch_to_window(browser.window_handles[0])browser.get('https://python.org') 异常处理12345from selenium import webdriver#异常处理browser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.find_element_by_id('hello') 加入异常处理 1234567891011121314from selenium import webdriverfrom selenium.common.exceptions import TimeoutException, NoSuchElementExceptionbrowser = webdriver.Chrome()try: browser.get('https://www.baidu.com')except TimeoutException: print('Time Out')try: browser.find_element_by_id('hello')except NoSuchElementException: print('No Element')finally: browser.close()]]></content>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeautifulSoup详解]]></title>
    <url>%2F2019%2F03%2F02%2FBeautifulSoup%2F</url>
    <content type="text"><![CDATA[BeautifulSoup详解BeautifulSoup是一个灵活有方便的网页解系库，处理搞笑，支持多种解析器，利用他可以不编写正贼表达式即可方便实现网页信息的提取。 解析库： 在此，我们主要用lxml解析器 标签选择器：123456789101112131415161718192021222324# coding=utf-8from bs4 import BeautifulSoup as bshtml = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;,&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;"""soup = bs(html, 'lxml')print(soup.title)print(type(soup.title))print(soup.head)print(type(soup.head))print(soup.p)print(type(soup.p)) 这里我们print了soup.title、head、p三个标签以及他们的类型，结果如下： 他们的类型都是bs.elment.tag，类型，类就是标签类型，并且对于soup.p，是把第一个p标签输出，也就是说有多个相同的标签，只输出第一个 获取名称： 1print(soup.title.name) 输出结果就是title 获取属性： 1print(soup.title.attrs['name']) 1print(soup.p['name']) 可以看到这两种方式都是相同的 获取内容： 1print(soup.p.string) 嵌套选择： 也就是说从body到p，是一个嵌套的关系，p也是说，通过 .head得到的tag还可以进一步 向下索取，通过.body.p得到p标签 子节点和子孙节点（children和contents）： contents： 1234567891011121314151617181920212223242526272829303132333435# coding=utf-8from bs4 import BeautifulSoup as bshtml = """ &lt;html&gt; &lt;head&gt; &lt;title&gt; The Dormouse's story &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt; Elsie &lt;/a&gt; , &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt; Lacie &lt;/a&gt; and &lt;a class="sister" href="http://example.com/tillie" id="link2"&gt; Tillie &lt;/a&gt; ; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class="story"&gt; ... &lt;/p&gt; &lt;/body&gt;&lt;/html&gt;"""soup = bs(html, 'lxml')print(soup.body.contents) 可以看到contents属性返回了一个列表，整个p中的内容。把所有的换行符 标签放进了列表 children: 当我们把contents换成children： 1print(soup.body.children) contents： 它返回了一个迭代器，需要用for循环遍历使用 后代descendants: 1print(soup.body.descendants) 还是一个迭代器，并且descendants是获得所有子孙节点，也就是儿子的儿子也会获得 父节点parent： 返回父节点 父节点parents: 兄弟节点siblings： 以上是标签选择器，是通过名字进行选择，但是在选择时候，往往会有很多名字相同的标签，所以我们不能完全用标签选择器进行选择，故引入标准选择器: 标准选择器： find_all(name, attrs, recursive, text, \kwargs)** 可根据标签名、属性、内容查找文档， 把所有符合条件的结果，并以列表的形式返回 name： 可以看到findall返回的列表中的每一个项哦都是tag类型 由此我们可以嵌套for循环： 12for p in soup.find_all('p'): print(p.find_all('a')) attrs： 12print(soup.find_all(attrs=&#123;'id': 'list-1'&#125;))print(soup.find_all(attrs=&#123;'name': 'elements'&#125;)) attr需要传入一个字典 并且对于某一些属性，可以直接用参数传入： 12print(soup.find_all(id='list-1'))print(soup.find_all(class_='elements')) #class 是python的一个关键词，所以我们用class_代替class text： 根据文本的内容选择，而它的返回值仅仅是文本的列表而不是tag find(name, attrs, recursive, text, \kwargs)** 与find_all不同是 find返回单个元素，fan_all返回所有元素。 find查找一个不存在的元素返回None find_parent()和find_parents(): find_parent()返回所有祖先节点，find_parent()返回直接父节点。 find_next_siblings() 和 find_next_sibling() find_next_siblings() 返回后面所有兄弟节点 find_next_sibling()返回前面一个兄弟节点 find_all_next() 和find_next() find_all_next()返回节点后所有符合条件的节点，find_next()返回第一个符合条件的节点 find_all_previous()和find_previous() find_all_previous()返回节点钱所有符合条件的节点，find_previous返回第一个符合条件的节点 css选择器通过css()直接传入css选择器即可完成选择 标签（什么都不用加）.属性（加点） #id（加井号） 12345678910111213141516171819202122232425262728293031323334353637import requests from bs4 import BeautifulSoup as bs html = """ &lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="title" name="dromouse"&gt; &lt;b&gt;The Dormouse's story&lt;/b&gt; &lt;/p&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a class="mysis" href="http://example.com/elsie" id="link1"&gt; &lt;b&gt;the first b tag&lt;b&gt; Elsie &lt;/a&gt;, &lt;a class="mysis" href="http://example.com/lacie" id="link2" myname="kong"&gt; Lacie &lt;/a&gt;and &lt;a class="mysis" href="http://example.com/tillie" id="link3"&gt; Tillie &lt;/a&gt;;and they lived at the bottom of a well. &lt;/p&gt; &lt;p class="story"&gt; myStory &lt;a&gt;the end a tag&lt;/a&gt; &lt;/p&gt; &lt;a&gt;the p tag sibling&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; """ soup = bs(html, 'lxml') print(soup.select('p')) print(soup.select('p a')) print(type(soup.select('p')[0])) 输出结果1是一个包含所有p标签的列表 2是一个包含所有p标签下的a标签的列表，3是class &#39;bs4.element.Tag&#39;，也就是说。css选择器生成的结果就是一个tag类型的列表。 同时对于soup.select(‘a.mysis‘表示class属性为mysis的所有标签。也即没有空格的表示有某一个属性的或者id的标签。 有空格代表是同等的 又因为select返回的是tag类型的列表，所以我们可以继续使用上面的方法获得属性即：、 12345for a in soup.select('p a'): #方法一 print(a['href']) #方法二 print(a.attrs['href']) 以下罗列出一些css选择器的方法：（以下内容转自https://www.cnblogs.com/kongzhagen/p/6472746.html） 1、通过标签选择 123456789101112# 选择所有title标签 soup.select("title") # 选择所有p标签中的第三个标签 soup.select("p:nth-of-type(3)") 相当于soup.select(p)[2] # 选择body标签下的所有a标签 soup.select("body a") # 选择body标签下的直接a子标签 soup.select("body &gt; a") # 选择id=link1后的所有兄弟节点标签 soup.select("#link1 ~ .mysis") # 选择id=link1后的下一个兄弟节点标签 soup.select("#link1 + .mysis") 2、通过类名查找 12# 选择a标签，其类属性为mysis的标签 soup.select("a.mysis") 3、通过id查找 12# 选择a标签，其id属性为link1的标签 soup.select("a#link1") 4、通过【属性】查找，当然也适用于class 1234567891011121314# 选择a标签，其属性中存在myname的所有标签 soup.select("a[myname]") # 选择a标签，其属性href=http://example.com/lacie的所有标签 soup.select("a[href='http://example.com/lacie']") # 选择a标签，其href属性以http开头 soup.select('a[href^="http"]') # 选择a标签，其href属性以lacie结尾 soup.select('a[href$="lacie"]') # 选择a标签，其href属性包含.com soup.select('a[href*=".com"]') # 从html中排除某标签，此时soup中不再有script标签 [s.extract() for s in soup('script')] # 如果想排除多个呢 [s.extract() for s in soup(['script','fram'] 5、获取文本及属性 12345678910111213141516171819202122232425html_doc = """&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt; &lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;, &lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and &lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;; &lt;/p&gt; and they lived at the bottom of a well. &lt;p class="story"&gt;...&lt;/p&gt; &lt;/body&gt; """ from bs4 import BeautifulSoup ''''' 以列表的形式返回 ''' soup = BeautifulSoup(html_doc, 'html.parser') s = soup.select('p.story') s[0].get_text() # p节点及子孙节点的文本内容 s[0].get_text("|") # 指定文本内容的分隔符 s[0].get_text("|", strip=True) # 去除文本内容前后的空白 print(s[0].get("class")) # p节点的class属性值列表（除class外都是返回字符串） 在创建 BeautifulSoup 或 UnicodeDammit 对象前一定要先对文档调用 UnicodeDammit.detwingle() 确保文档的编码方式正确.如果尝试去解析一段包含Windows-1252编码的UTF-8文档,就会得到一堆乱码,比如: â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”. 6、其他 123456789101112131415161718192021222324252627282930313233343536html_doc = """&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt; &lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;, &lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and &lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;; &lt;/p&gt; and they lived at the bottom of a well. &lt;p class="story"&gt;...&lt;/p&gt; &lt;/body&gt; """ from bs4 import BeautifulSoup ''''' 以列表的形式返回 ''' soup = BeautifulSoup(html_doc, 'html.parser') soup.select('title') # title标签 soup.select("p:nth-of-type(3)") # 第三个p节点 soup.select('body a') # body下的所有子孙a节点 soup.select('p &gt; a') # 所有p节点下的所有a直接节点 soup.select('p &gt; #link1') # 所有p节点下的id=link1的直接子节点 soup.select('#link1 ~ .sister') # id为link1的节点后面class=sister的所有兄弟节点 soup.select('#link1 + .sister') # id为link1的节点后面class=sister的第一个兄弟节点 soup.select('.sister') # class=sister的所有节点 soup.select('[class="sister"]') # class=sister的所有节点 soup.select("#link1") # id=link1的节点 soup.select("a#link1") # a节点，且id=link1的节点 soup.select('a[href]') # 所有的a节点，有href属性 soup.select('a[href="http://example.com/elsie"]') # 指定href属性值的所有a节点 soup.select('a[href^="http://example.com/"]') # href属性以指定值开头的所有a节点 soup.select('a[href$="tillie"]') # href属性以指定值结尾的所有a节点 soup.select('a[href*=".com/el"]') # 支持正则匹配]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2019%2F03%2F02%2Fregex%2F</url>
    <content type="text"><![CDATA[常见匹配模式 模式 描述 \w 匹配字母数字及下划线 \W 匹配非字母数字下划线 \s 匹配任意空白字符，等价于 [\t\n\r\f]. \S 匹配任意非空字符 \d 匹配任意数字，等价于 [0-9] \D 匹配任意非数字 \A 匹配字符串开始 \Z 匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串 \z 匹配字符串结束 \G 匹配最后匹配完成的位置 \n 匹配一个换行符 \t 匹配一个制表符 ^ 匹配字符串的开头 $ 匹配字符串的末尾。 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’ [^…] 不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。 * 匹配0个或多个的表达式。 + 匹配1个或多个的表达式。 ? 匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式 {n} 精确匹配n个前面表达式。 {n, m} 匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式 a&#124;b 匹配a或b ( ) 匹配括号内的表达式，也表示一个组 re.match re.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。 1re.match(pattern, string, flags=0) 最常规的匹配12345678import re content = 'Hello 123 4567 World_This is a Regex Demo' print(len(content)) result = re.match('^Hello\s\d\d\d\s\d&#123;4&#125;\s\w&#123;10&#125;.*Demo$', content) print(result) print(result.group(0)) print(result.span()) RESULT: 1234&gt; &lt;_sre.SRE_Match object; span=(0, 41), match=&apos;Hello 123 4567 World_This is a Regex Demo&apos;&gt;&gt; Hello 123 4567 World_This is a Regex Demo&gt; (0, 41)&gt; 匹配目标1234567import recontent = 'Hello 1234567 World_This is a Regex Demo'result = re.match('^Hello\s(\d+)\sWorld.*Demo$', content)print(result)print(result.group(1))print(result.span()) RESULT: 1234&gt; &lt;re.Match object; span=(0, 40), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt;&gt; 1234567&gt; (0, 40)&gt; 匹配模式re.S它表示“.”（不包含外侧双引号，下同）的作用扩展到整个字符串，包括“\n”。看如下代码： 1234567import recontent = '''Hello 1234567 World_Thisis a Regex Demo'''result = re.match('^He.*?(\d+).*?Demo$', content, re.S)print(result.group(1)) RESULT: 1234567 re.searchre.search 扫描整个字符串并返回第一个成功的匹配。 12345import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'result = re.match('Hello.*?(\d+).*?Demo', content)print(result) RESULT: None 123456import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'result = re.search('Hello.*?(\d+).*?Demo', content)print(result)print(result.group(1)) RESULT: 123&gt; &lt;_sre.SRE_Match object; span=(13, 53), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt;&gt; 1234567&gt; re.match和re.search的差异： 总结：为匹配方便，能用search就不用match 匹配演练12345678910111213141516171819202122232425import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;&lt;i class="fa fa-user"&gt;&lt;/i&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?active.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)if result: print(result.group(1), result.group(2), result.group(), sep='\n') RESULT: 123456789&gt; 齐秦&gt; 往事随风&gt; &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;&gt; &lt;li data-view=&quot;7&quot;&gt;&gt; &lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;沧海一声笑&lt;/a&gt;&gt; &lt;/li&gt;&gt; &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;&gt; &lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;往事随风&lt;/a&gt;&gt; 12345678910111213141516171819202122232425262728import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)if result: print(result.group(1), result.group(2)) RESULT: 12&gt; 任贤齐 沧海一声笑&gt; 12345678910111213141516171819202122232425262728import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html)if result: print(result.group(1), result.group(2)) RESULT: 12&gt; beyond 光辉岁月&gt; re.findall搜索字符串，以列表形式返回全部能匹配的子串。 1234567891011121314151617181920212223242526272829303132import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall('&lt;li.*?href="(.*?)".*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)print(results)print(type(results))for result in results: print(result) print(result[0], result[1], result[2]) print(type(result[0]), type(result), type(results)) RESULT: 123456789101112131415161718&gt; [(&apos;/2.mp3&apos;, &apos;任贤齐&apos;, &apos;沧海一声笑&apos;), (&apos;/3.mp3&apos;, &apos;齐秦&apos;, &apos;往事随风&apos;), (&apos;/4.mp3&apos;, &apos;beyond&apos;, &apos;光辉岁月&apos;), (&apos;/5.mp3&apos;, &apos;陈慧琳&apos;, &apos;记事本&apos;), (&apos;/6.mp3&apos;, &apos;邓丽君&apos;, &apos;但愿人长久&apos;)]&gt; &lt;class &apos;list&apos;&gt;&gt; (&apos;/2.mp3&apos;, &apos;任贤齐&apos;, &apos;沧海一声笑&apos;)&gt; /2.mp3 任贤齐 沧海一声笑&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;list&apos;&gt;&gt; (&apos;/3.mp3&apos;, &apos;齐秦&apos;, &apos;往事随风&apos;)&gt; /3.mp3 齐秦 往事随风&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;list&apos;&gt;&gt; (&apos;/4.mp3&apos;, &apos;beyond&apos;, &apos;光辉岁月&apos;)&gt; /4.mp3 beyond 光辉岁月&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;list&apos;&gt;&gt; (&apos;/5.mp3&apos;, &apos;陈慧琳&apos;, &apos;记事本&apos;)&gt; /5.mp3 陈慧琳 记事本&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;list&apos;&gt;&gt; (&apos;/6.mp3&apos;, &apos;邓丽君&apos;, &apos;但愿人长久&apos;)&gt; /6.mp3 邓丽君 但愿人长久&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;list&apos;&gt;&gt; 123456789101112131415161718192021222324252627282930import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall('&lt;li.*?&gt;\s*?(&lt;a.*?&gt;)?(\w+)(&lt;/a&gt;)?\s*?&lt;/li&gt;', html, re.S)print(results)for result in results: print(result[1]) RESULT: 12345678&gt; [(&apos;&apos;, &apos;一路上有你&apos;, &apos;&apos;), (&apos;&lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;&apos;, &apos;沧海一声笑&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;&apos;, &apos;往事随风&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;&apos;, &apos;光辉岁月&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;&apos;, &apos;记事本&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;&apos;, &apos;但愿人长久&apos;, &apos;&lt;/a&gt;&apos;)]&gt; 一路上有你&gt; 沧海一声笑&gt; 往事随风&gt; 光辉岁月&gt; 记事本&gt; 但愿人长久&gt; re.sub替换字符串中每一个匹配的子串后返回替换后的字符串。 12345import recontent = 'Extra stings Hello 1234567 World_This is 4567890 a Regex Demo Extra stings'content = re.sub('\d+', '', content)print(content) RESULT: 12&gt; Extra stings Hello World_This is a Regex Demo Extra stings&gt; 12345import recontent = 'Extra stings Hello | 1234567 | 891011 | World_This is a Regex Demo Extra stings'content = re.sub('(\d+)', r'\1 New \1', content)print(content) RESULT: 12&gt; Extra stings Hello | 1234567 New 1234567 | 891011 New 891011 | World_This is a Regex Demo Extra stings&gt; 1234567891011121314151617181920212223242526272829303132import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''html = re.sub('&lt;a.*?&gt;|&lt;/a&gt;', '', html)print(html)results = re.findall('&lt;li.*?&gt;(.*?)&lt;/li&gt;', html, re.S)print(results)for result in results: print(result.strip()) RESULT: 12345678910111213141516171819202122232425262728&gt; &lt;div id=&quot;songs-list&quot;&gt;&gt; &lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt;&gt; &lt;p class=&quot;introduction&quot;&gt;&gt; 经典老歌列表&gt; &lt;/p&gt;&gt; &lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt;&gt; &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt;&gt; &lt;li data-view=&quot;7&quot;&gt;&gt; 沧海一声笑&gt; &lt;/li&gt;&gt; &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt;&gt; 往事随风&gt; &lt;/li&gt;&gt; &lt;li data-view=&quot;6&quot;&gt;光辉岁月&lt;/li&gt;&gt; &lt;li data-view=&quot;5&quot;&gt;记事本&lt;/li&gt;&gt; &lt;li data-view=&quot;5&quot;&gt;&gt; 但愿人长久&gt; &lt;/li&gt;&gt; &lt;/ul&gt;&gt; &lt;/div&gt;&gt; [&apos;一路上有你&apos;, &apos;\n 沧海一声笑\n &apos;, &apos;\n 往事随风\n &apos;, &apos;光辉岁月&apos;, &apos;记事本&apos;, &apos;\n 但愿人长久\n &apos;]&gt; 一路上有你&gt; 沧海一声笑&gt; 往事随风&gt; 光辉岁月&gt; 记事本&gt; 但愿人长久&gt; re.compile将一个正则表达式串编译成正则对象，以便于复用该匹配模式 12345678import recontent = '''Hello 1234567 World_Thisis a Regex Demo'''pattern = re.compile('Hello.*Demo', re.S)result = re.match(pattern, content)#result = re.match('Hello.*Demo', content, re.S)print(result) RESULT: 12&gt; &lt;_sre.SRE_Match object; span=(0, 40), match=&apos;Hello 1234567 World_This\nis a Regex Demo&apos;&gt;&gt; 实战练习12345678910import requestsimport recontent = requests.get('https://book.douban.com/').textpattern = re.compile('&lt;li.*?cover.*?href="(.*?)".*?title="(.*?)".*?more-meta.*?author"&gt;(.*?)&lt;/span&gt;.*?year"&gt;(.*?)&lt;/span&gt;.*?&lt;/li&gt;', re.S)results = re.findall(pattern, content)for result in results: url, name, author, date = result author = re.sub('\s', '', author) date = re.sub('\s', '', date) print(url, name, author, date)]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests]]></title>
    <url>%2F2019%2F03%2F01%2Frequests%2F</url>
    <content type="text"><![CDATA[requestsGET请求：带参数的url请求： 123import requestsdata =&#123;'name':'cheng','age':20&#125; #参数response = requests.get('https://httpbin.org/get', params=data) 这样requests会给我们自动build这个网址，查看response.url 这个属性。会得到我们请求的代码 ‘https://httpbin.org/get?name=cheng&amp;age=20&#39; 解析JSON：requests还提供了一个解析json的方法，用get方法请求 https://httpbin.org/get，它的返回结果是一个json的字符串，所以我们可以直接调用response.json方法得到。 ;) 1234567# coding=utf-8import jsonimport requestsresponse = requests.get('https://httpbin.org/get')print(response.json()) #调用json方法print(json.loads(response.text)) 用json.loads把json数据转化字典方法，同样打印输出，发现和response.json()是一样的，其实response.json()就是通过一个json.loads()方法 获取二进制数据​ Requests 会自动解码来自服务器的内容。大多数 unicode 字符集都能被无缝地解码。请求发出后，Requests 会基于 HTTP 头部对响应的编码作出有根据的推测。当你访问 r.text 之时，Requests 会使用其推测的文本编码。你可以找出 Requests 使用了什么编码，并且能够使用r.encoding 属性来改变它。 response.content()方法可以使你也能以字节的方式访问请求响应体，对于一些图片和视频 音频内容，需要用到content https://ssl.gstatic.com/ui/v1/icons/mail/rfr/logo_gmail_lockup_default_1x.png 是一张gmail的图片 通过储存content属性就可以获得图片 1234567# coding=utf-8import jsonimport requestsresponse = requests.get('https://ssl.gstatic.com/ui/v1/icons/mail/rfr/logo_gmail_lockup_default_1x.png')with open('gmail.png','wb') as f: #注意这边是二进制的写入所以是wb f.write(response.content) f.close() 成功写入了图片 添加headers一些网站会检测请求方是不是机器，如果是机器，就不能成功访问，所以要添加headers伪装成浏览器 123456# coding=utf-8import requestsheaders = &#123; 'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.92 Safari/537.36'&#125;response = requests.get('https://www.zhihu.com/', headers=headers) 添加上headers后的requests就可以伪装成浏览器了 post请求 123456# coding=utf-8import requestsdata = &#123;'name':'cheng', 'age':20&#125; #response = requests.post('https://httpbin.org/post', data=data)print(response.text) 发送了post请求，返回结果： 可以看到服务器接受了我们post的data，返回了一个json格式的数据. response常用属性123456789# coding=utf-8import requestsresponse = requests.get('http://www.cnki.net/old/')print(type(response.status_code), response.status_code)print(type(response.headers), response.status_code)print(type(response.cookies), response.cookies)print(type(response.url), response.url)print(type(response.history), response.history) 输出结果： 可以看到服务器返回的状态码是int类型的数据，headers是一个字典类型，cookies ，请求的网址是一个字符串类型，history是浏览的历史 文件上传：123456# coding=utf-8import requestsfile = &#123;'file' :open('img.jpg', 'rb')&#125;response = requests.post('https://httpbin.org/')print(response.text) 返回的结果中有file这个字典键值，对应的是我们上传的文件 cookies：response.cookies是一个字典的形式，我们可以通过for循环把他们print出来 12345678# coding=utf-8import requestsresponse = requests.get('https://www.baidu.com/')print(response)print(response.cookies)for key,value in response.cookies.items(): print(key + '=' + value) 运行结果： 会话维持——session模拟登陆 普通的get方式： 123456# coding=utf-8import requestsrequests.get('https://httpbin.org/cookies/set/number/123456')response = requests.get('https://httpbin.org/cookies')print(response.text) 这里，我们第一次请求网站，设置cookies，当第二次请求是，返回结果是： 可以看到第二次请求的cookies是空，原因是我们发起了两次请求，这两个请求是完全独立的过程，他们两个是没有相关性的，可以把他们想象成用两个浏览器分别访问，相当于模拟了一个会话。 用session请求： 1234567# coding=utf-8import requestss = requests.session()s.get('https://httpbin.org/cookies/set/number/123456')response = s.get('https://httpbin.org/cookies')print(response.text) 运行结果： 可以看到第二次请求的返回值就是第一次设置的值，可以把他们看作一个浏览器先后发出了请求,会话对象让你能够跨请求保持某些参数 证书验证：有些网站访问时会出现证书错误的情况： 有两种方式可以解决： 一种是修改requests中的varify参数，使他为false： 123456# coding=utf-8import requestsimport urllib3urllib3.disable_warnings()response = requests.get('http://www.12306.cn', verify=False) 这样访问时会自动忽略网站的证书。但是requests还是用生成warning，提醒你证书是不安全的我们导入urllib3模块，用disable_warnings()方法 第二种是直接指定一个证书： 1234# coding=utf-8import requestsresponse = requests.get('http://www.12306.cn', cert('path/server')) 代理设置1234567import requestsproxies = &#123; 'https': 'https://127.0.0.1:13386', 'http':'https://127.0.0.1:12345'&#125;response = requests.get('https://www.google.com/?hl=zh_cn', proxies=proxies) 直接添加一个proxies的字典就行当代理有密码时，只要在修改values值，添加上用户名和密码 123456import requestsproxies = &#123; 'https': 'https://user:password@127.0.0.1:13386',&#125;response = requests.get('https://www.google.com/',proxies=proxies) 如果是shadowsocks可以 pip install requests[socks] 然后将proxies修改成： 123456import requestsproxies = &#123; 'https': 'socks5:330330://127.0.0.1:13386',&#125;response = requests.get('https://www.baidu.com/', proxies=proxies) 超时设置1234import requestsresponse = requests.get('https://www.baidu.com/', timeout=0.2)print(response.status_code) 限制了响应时间，如果大于0.2秒，会抛出异常 认证设置123456import requestsfrom requests.auth import HTTPBasicAuthresponse = requests.get(url, auth=HTTPBasicAuth('usr','password'))response = requests.get(url, auth=&#123;'user':'12345'&#125;)print(response.status_code) 这样的两种auth属性都行 异常处理 exception requests.RequestException(*args, **kwargs)[源代码]¶There was an ambiguous exception that occurred while handling your request. exception requests.ConnectionError(*args, **kwargs)[源代码]A Connection error occurred. exception requests.HTTPError(*args, **kwargs)[源代码]An HTTP error occurred. exception requests.URLRequired(*args, **kwargs)[源代码]A valid URL is required to make a request. exception requests.TooManyRedirects(*args, **kwargs)[源代码]Too many redirects. exception requests.ConnectTimeout(*args, **kwargs)[源代码]The request timed out while trying to connect to the remote server.Requests that produced this error are safe to retry. exception requests.ReadTimeout(*args, **kwargs)[源代码]The server did not send any data in the allotted amount of time. exception requests.Timeout(*args, **kwargs)[源代码]The request timed out.Catching this error will catch both ConnectTimeout and ReadTimeout errors.]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vimcmd]]></title>
    <url>%2F2019%2F02%2F17%2Fvimcmd%2F</url>
    <content type="text"><![CDATA[### vim 选择文本，删除，复制，粘贴 文本的选择，对于编辑器来说，是很基本的东西，也经常被用到，总结如下： v 从光标当前位置开始，光标所经过的地方会被选中，再按一下v结束。 V 从光标当前行开始，光标经过的行都会被选中，再按一下Ｖ结束。 Ctrl + v 从光标当前位置开始，选中光标起点和终点所构成的矩形区域，再按一下Ｃtrl + v结束。 ggVG 选中全部的文本， 其中gg为跳到行首，V选中整行，G末尾 选中后就可以用编辑命令对其进行编辑，如d 删除 y 复制 （默认是复制到”寄存器） p 粘贴 （默认从”寄存器取出内容粘贴） “+y 复制到系统剪贴板(也就是vim的+寄存器） “+p 从系统剪贴板粘贴 vim命令总结 1.删除字符 要删除一个字符，只需要将光标移到该字符上按下”x”。 2.删除一行 删除一整行内容使用”dd”命令。删除后下面的行会移上来填补空缺。 3.删除换行符 在Vim中你可以把两行合并为一行，也就是说两行之间的换行符被删除了：命令是”J”。 4.撤销 如果你误删了过多的内容。显然你可以再输入一遍，但是命令”u” 更简便，它可以撤消上一次的操作。 5.重做: 如果你撤消了多次，你还可以用CTRL-R(重做)来反转撤消的动作。换句话说，它是对撤消的撤消。撤消命令还有另一种形式，”U”命令，它一次撤消对一行的全部操作。第二次使用该命令则会撤消前一个”U”的操作。用”u”和CTRL-R你可以找回任何一个操作状态。 6.追加 “i”命令可以在当前光标之前插入文本。 “a”命令可以在当前光标之后插入文本。 “o”命令可以在当前行的下面另起一行，并使当前模式转为Insert模式。 “O”命令(注意是大写的字母O)将在当前行的上面另起一行。 7.使用命令计数 假设你要向上移动9行。这可以用”kkkkkkkkk”或”9k”来完成。事实上，很多命令都可以接受一个数字作为重复执行同一命令的次数。比如刚才的例子，要在行尾追加三个感叹号，当时用的命令是”a!!!”。另一个办法是用”3a!”命令。3说明该命令将被重复执行3次。同样，删除3个字符可以用”3x”。指定的数字要紧挨在它所要修饰的命令前面。 8.退出 要退出Vim，用命令”ZZ”。该命令保存当前文件并退出Vim。 9.放弃编辑 丢弃所有的修改并退出，用命令”:q!”。用”:e!”命令放弃所有修改并重新载入该文件的原始内容。 10.以Word为单位的移动 使用”w”命令可以将光标向前移动一个word的首字符上；比如”3w”将光标向前移动3个words。”b”命令则将光标向后移动到前一个word的首字符上。 “e”命令会将光标移动到下一个word的最后一个字符。命令”ge”，它将光标移动到前一个word的最后一个字符上。、 11.移动到行首或行尾 “$”命令将光标移动到当前行行尾。如果你的键盘上有一个键，它的作用也一样。”^”命令将光标移动到当前行的第一个非空白字符上。”0”命令则总是把光标移动到当前行的第一个字符上。键也是如此。”$”命令还可接受一个计数，如”1$”会将光标移动到当前行行尾，”2$”则会移动到下一行的行尾，如此类推。”0”命令却不能接受类似这样的计数，命令”^”前加上一个计数也没有任何效果。 12.移动到指定字符上 命令”fx”在当前行上查找下一个字符x（向右方向），可以带一个命令计数”F”命令向左方向搜索。”tx”命令形同”fx”命令，只不过它不是把光标停留在被搜索字符上，而是在它之前的一个字符上。提示：”t”意为”To”。该命令的反方向版是”Tx”。这4个命令都可以用”;”来重复。以”,”也是重复同样的命令，但是方向与原命令的方向相反。 13.以匹配一个括号为目的移动 用命令”%”跳转到与当前光标下的括号相匹配的那一个括号上去。如果当前光标在”(“上，它就向前跳转到与它匹配的”)”上，如果当前在”)”上，它就向后自动跳转到匹配的”(“上去. 14.移动到指定行 用”G”命令指定一个命令计数，这个命令就会把光标定位到由命令计数指定的行上。比如”33G”就会把光标置于第33行上。没有指定命令计数作为参数的话, “G”会把光标定位到最后一行上。”gg”命令是跳转到第一行的快捷的方法。 另一个移动到某行的方法是在命令”%”之前指定一个命令计数比如”50%”将会把光标定位在文件的中间. “90%”跳到接近文件尾的地方。 命令”H”,”M”,”L”,分别将光标跳转到第一行，中间行，结尾行部分。 15.告诉你当前的位置 使用CTRL-G命令。”set number”在每行的前面显示一个行号。相反关闭行号用命令”:set nonumber”。”:set ruler”在Vim窗口的右下角显示当前光标位置。 16.滚屏 CTRL-U显示文本的窗口向上滚动了半屏。CTRL-D命令将窗口向下移动半屏。一次滚动一行可以使用CTRL-E(向上滚动)和CTRL-Y(向下滚动)。要向前滚动一整屏使用命令CTRL-F。另外CTRL-B是它的反向版。”zz”命令会把当前行置为屏幕正中央，”zt”命令会把当前行置于屏幕顶端，”zb”则把当前行置于屏幕底端. 17.简单搜索 “/string”命令可用于搜索一个字符串。要查找上次查找的字符串的下一个位置,使用”n”命令。如果你知道你要找的确切位置是目标字符串的第几次出现，还可以在”n”之前放置一个命令计数。”3n”会去查找目标字符串的第3次出现。 “?”命令与”/“的工作相同，只是搜索方向相反.”N”命令会重复前一次查找，但是与最初用”/“或”?”指定的搜索方向相反。 如果查找内容忽略大小写，则用命令”set ignorecase”, 返回精确匹配用命令”set noignorecase” 。 18.在文本中查找下一个word 把光标定位于这个word上然后按下”“键。Vim将会取当前光标所在的word并将它作用目标字符串进行搜索。”#”命令是”“的反向版。还可以在这两个命令前加一个命令计数:”3*”查找当前光标下的word的第三次出现。 19.查找整个word 如果你用”/the”来查找Vim也会匹配到”there”。要查找作为独立单词的”the”使用如下命令：”/the>“。”>“是一个特殊的记法，它只匹配一个word的结束处。近似地，”\&lt;”匹配到一个word的开始处。这样查找作为一个word的”the”就可以用:”/\”。 20.高亮显示搜索结果 开启这一功能用”:set hlsearch”，关闭这一功能：”:set nohlsearch”。如果只是想去掉当前的高亮显示，可以使用下面的命令：”:nohlsearch”(可以简写为noh)。 21.匹配一行的开头与结尾 ^ 字符匹配一行的开头。$字符匹配一行的末尾。 所以”/was$”只匹配位于一行末尾的单词was，所以”/^was”只匹配位于一行开始的单词was。 22.匹配任何的单字符 .这个字符可以匹配到任何字符。比如”c.m”可以匹配任何前一个字符是c，后一个字符是m的情况，不管中间的字符是什么。 23.匹配特殊字符 放一个反斜杠在特殊字符前面。如果你查找”ter。”，用命令”/ter\。” 24.使用标记 当你用”G”命令从一个地方跳转到另一个地方时，Vim会记得你起跳的位置。这个位置在Vim中是一个标记。使用命令” &quot;可以使你跳回到刚才的出发点。命令可以在两点之间来回跳转。CTRL-O命令是跳转到你更早些时间停置光标的位置(提示:O意为older). CTRL-I则是跳回到后来停置光标的更新的位置(提示：I在键盘上位于O前面)。 注:使用CTRL-I 与按下键一样。 25.具名标记 命令”ma”将当前光标下的位置名之为标记”a”。从a到z一共可以使用26个自定义的标记。要跳转到一个你定义过的标记，使用命令” marks &quot;marks就是定义的标记的名字。命令&quot; &#39;a &quot;使你跳转到a所在行的行首，&quot;a “会精确定位a所在的位置。命令：”:marks”用来查看标记的列表。 命令delm！删除所有标记。 26.操作符命令和位移 “dw”命令可以删除一个word，”d4w”命令是删除4个word，依此类推。类似有”d2e”、”d$”。此类命令有一个固定的模式：操作符命令+位移命令。首先键入一个操作符命令。比如”d”是一个删除操作符。接下来是一个位移命。比如”w”。这样任何移动光标命令所及之处，都是命令的作用范围。 27.改变文本 操作符命令是”c”，改变命令。它的行为与”d”命令类似，不过在命令执行后会进入Insert模式。比如”cw”改变一个word。或者，更准确地说，它删除一个word并让你置身于Insert模式。 “cc”命令可以改变整行。不过仍保持原来的缩进。 “c$”改变当前光标到行尾的内容。 快捷命令：x 代表dl(删除当前光标下的字符) X 代表dh(删除当前光标左边的字符) D 代表d$(删除到行尾的内容) C 代表c$(修改到行尾的内容) s 代表cl(修改一个字符) S 代表cc(修改一整行) 命令”3dw”和”d3w”都是删除3个word。第一个命令”3dw”可以看作是删除一个word的操作执行3次；第二个命令”d3w”是一次删除3个word。这是其中不明显的差异。事实上你可以在两处都放上命令记数，比如，”3d2w”是删除两个word，重复执行3次，总共是6个word。 28.替换单个字符 “r”命令不是一个操作符命令。它等待你键入下一个字符用以替换当前光标下的那个字符。”r”命令前辍以一个命令记数是将多个字符都替换为即将输入的那个字符。要把一个字符替换为一个换行符使用”r”。它会删除一个字符并插入一个换行符。在此处使用命令记数只会删除指定个数的字符：”4r”将把4个字符替换为一个换行符。 29.重复改动 “.”命令会重复上一次做出的改动。”.”命令会重复你做出的所有修改，除了”u”命令CTRL-R和以冒号开头的命令。”.”需要在Normal模式下执行，它重复的是命令，而不是被改动的内容， 30.Visual模式 按”v”可以进入Visual模式。移动光标以覆盖你想操纵的文本范围。同时被选中的文本会以高亮显示。最后键入操作符命令。 31.移动文本 以”d”或”x”这样的命令删除文本时，被删除的内容还是被保存了起来。你还可以用p命令把它取回来。”P”命令是把被去回的内容放在光标之前，”p”则是放在光标之后。对于以”dd”删除的整行内容，”P”会把它置于当前行的上一行。”p”则是至于当前行的后一行。也可以对命令”p”和”P”命令使用命令记数。它的效果是同样的内容被取回指定的次数。这样一来”dd”之后的”3p”就可以把被删除行的3 份副本放到当前位置。 命令”xp”将光标所在的字符与后一个字符交换。 32.**复制文本（VIM编辑器内复制）** “y”操作符命令会把文本复制到一个寄存器3中。然后可以用”p”命令把它取回。因为”y”是一个操作符命令，所以你可以用”yw”来复制一个word. 同样可以使用命令记数。如下例中用”y2w”命令复制两个word，”yy”命令复制一整行，”Y”也是复制整行的内容，复制当前光标至行尾的命令是”y$”。 33.文本对象 “diw” 删除当前光标所在的word(不包括空白字符) “daw” 删除当前光标所在的word(包括空白字符) 34.快捷命令 x 删除当前光标下的字符(“dl”的快捷命令) X 删除当前光标之前的字符(“dh”的快捷命令) D 删除自当前光标至行尾的内容(“d$”的快捷命令) dw 删除自当前光标至下一个word的开头 db 删除自当前光标至前一个word的开始 diw 删除当前光标所在的word(不包括空白字符) daw 删除当前光标所在的word(包括空白字符) dG 删除当前行至文件尾的内容 dgg 删除当前行至文件头的内容 如果你用”c”命令代替”d”这些命令就都变成更改命令。使用”y”就是yank命令，如此类推。 35.编辑另一个文件 用命令”:edit foo.txt”，也可简写为”:e foo.txt”。 36.文件列表 可以在启动Vim时就指定要编辑多个文件，用命令”vim one.c two.c three.c”。Vim将在启动后只显示第一个文件，完成该文件的编辑后，可以用令：”:next”或”:n”要保存工作成果并继续下一个文件的编辑，命令：”:wnext”或”:wn”可以合并这一过程。 37.显示当前正在编辑的文件 用命令”:args”。 38.移动到另一个文件 用命令”:previous” “:prev”回到上一个文件,合并保存步骤则是”:wprevious” “:wprev”。要移到最后一个文件”:last”,到第一个”:first”.不过没有”:wlast”或者”:wfirst”这样的命令。可以在”:next”和”:previous”命令前面使用一个命令计数。 39.编辑另一个文件列表 不用重新启动Vim，就可以重新定义一个文件列表。命令”:args five.c six.c seven.h”定义了要编辑的三个文件。 39.自动存盘 命令”:set autowrite”,”set aw”。自动把内容写回文件: 如果文件被修改过，在每个:next、:rewind、:last、:first、:previous、:stop、:suspend、:tag、:!、:make、CTRL-] 和 CTRL-^命令时进行。 命令”:set autowriteall”,”set awa”。和 ‘autowrite’ 类似，但也适用于”:edit”、”:enew”、”:quit”、”:qall”、”:exit”、”:xit”、”:recover” 和关闭 Vim 窗口。置位本选项也意味着 Vim 的行为就像打开 ‘autowrite’ 一样。 40.切换到另一文件 要在两个文件间快速切换，使用CTRL-^。 41.文件标记 以大写字母命名的标记。它们是全局标记，它们可以用在任何文件中。比如，正在编辑”fab1.Java“,用命令”50%mF”在文件的中间设置一个名为F的标记。然后在”fab2.java”文件中，用命令”GnB”在最后一行设置名为B的标记。在可以用”F”命令跳转到文件”fab1.java”的半中间。或者编辑另一个文件，”‘B”命令会再把你带回文件”fab2.java”的最后一行。 要知道某个标记所代表的位置是什么，可以将该标记的名字作为”marks”命令的参数”:marks M”或者连续跟上几个参数”:marks MJK” 可以用CTRL-O和CTRL-I可以跳转到较早的位置和靠后的某位置。 42.查看文件 仅是查看文件，不向文件写入内容，可以用只读形式编辑文件。用命令：vim -R file。如果是想强制性地避免对文件进行修改，可以用命令：vim -M file。 43.更改文件名 将现有文件存成新的文件，用命令”:sav(eas) move.c”。如果想改变当前正在编辑的文件名，但不想保存该文件，就可以用命令：”:f(ile) move.c”。 44.分割一个窗口 打开一个新窗口最简单的办法就是使用命令：”:split”。CTRL-W 命令可以切换当前活动窗口。 45.关闭窗口 用命令：”close”.可以关闭当前窗口。实际上,任何退出文件编辑的命令”:quit”和”ZZ”都会关闭窗口，但是用”:close”可以阻止你关闭最后一个Vim，以免以意外地整个关闭了Vim。 46.关闭除当前窗口外的所有其他窗口 用命令：”:only”,关闭除当前窗口外的所有其它窗口。如果这些窗口中有被修改过的，你会得到一个错误信息，同时那个窗口会被留下来。 47.为另一个文件分隔出一个窗口 命令”:split two.c”可以打开第二个窗口同时在新打开的窗口中开始编辑作为参数的文件。如果要打开一个新窗口并开始编辑一个空的缓冲区，使用命令:”:new”。 48.垂直分割 用命令”:vsplit或：:vsplit two.c”。同样有一个对应的”:vnew”命令，用于垂直分隔窗口并在其中打开一个新的空缓冲区。 49.切换窗口 CTRL-W h 到左边的窗口 CTRL-W j 到下面的窗口 CTRL-W k 到上面的窗口 CTRL-W l 到右边的窗口 CTRL-W t 到顶部窗口 CTRL-W b 到底部窗口 50.针对所有窗口操作的命令 “:qall”放弃所有操作并退出，”:wall”保存所有，”:wqall”保存所有并退出。 51.为每一个文件打开一个窗口 使用”-o”选项可以让Vim为每一个文件打开一个窗口：“vim -o one.txt two.txt three.txt”。 52.使用vimdiff查看不同 “vimdiff main.c~ main.c”,另一种进入diff模式的办法可以在Vim运行中操作。编辑文件”main.c”，然后打开另一个分隔窗口显示其不同: “:edit main.c” “:vertical diffpatch main.c.diff”。53.页签 命令”:tabe(dit) thatfile”在一个窗口中打开”thatfile”，该窗口占据着整个的Vim显示区域。命令”:tab split/new”结果是新建了一个拥有一个窗口的页签。以用”gt”命令在不同的页签间切换。]]></content>
      <categories>
        <category>vim</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[django-vuejs-api-views]]></title>
    <url>%2F2019%2F01%2F02%2Fdjango-vuejs-api-views%2F</url>
    <content type="text"><![CDATA[Translation Table English Chinese front-end 前端 back-end 后端 pagination 分页 tweaking 拧（这里应该是修改的意思） queries 查询 Decimal 十进制 querysets 查询集 Building a Modern Web Application with Django REST Framework and Vue: Building Views and REST APIThroughout this part of these tutorial series you will continue developing a CRUD (Create, Read, Update and Delete) application with a restful API back-end and a Vue front-end using Django, Django REST framework and Vue (with Axios as an HTTP client). In this part you’ll specifically build the REST API and the front-end views to consume and display data from the API endpoints. You will also see how to integrate your Vue application with your Django back-end in production. As always you can find the source code of the demo project in this Github repository. You can check the second article from this link Building the REST API: You will create a simple REST API around one model (Product) with DRF(Django REST Framework) and learn how to add pagination to your APIs. Creating the Service to Consume the API: You will create the class that interfaces with your API using Axios. Creating the Front End Views: You will create different views and routes for the Vue application and see how you can protect some routes from non authenticated users. Getting Ready for Production: Finally you’ll prepare your app for production by tweaking some settings in Vue and Django parts. Building the REST APIDjango REST framework is a powerful and easy to use package for building Web APIs. Let’s get started by building a simple REST API using Django REST framework. Adding the Product ModelDjango has a powerful ORM (Object Relational Mapper) that allows you to work with multiple database management systems without actually writing any SQL. All you need to do is to define models in Python classes and Django will take care of mapping Python classes to SQL queries. The API is built around a simple product model so continuing with the project you’ve built in the previous part open the catalog/models.py file then add the following model 123456789101112131415161718192021222324from django.db import modelsclass Product(models.Model): sku = models.CharField(max_length=13,help_text="Enter Stock Keeping Unit") name = models.CharField(max_length=200, help_text="Enter product name") description = models.TextField(help_text="Enter product description") buyPrice = models.DecimalField(decimal_places=2, max_digits=20,help_text="Enter product price per unit") sellPrice = models.DecimalField(decimal_places=2, max_digits=20,help_text="Enter product price per unit") unit = models.CharField(max_length=10,help_text="Enter product unit") quantity = models.DecimalField(decimal_places=1, max_digits=20,help_text="Enter quantity") def get_absolute_url(self): """ Returns the url to access a particular instance of Product. """ return reverse('product-detail-view', args=[str(self.id)]) def __str__(self): return self.sku This is a Python class that extends the special Django class Model which is imported from the django.db.models built-in package. Every Django model needs to extends the Modelclass. You then specify the model fields using classes like CharField, TextField and DecimalField etc. Now you need to migrate your database to add the new changes 12python manage.py makemigrationspython manage.py migrate Next let’s add some seed data using a data migration So first make an empty migration by running the following command: 1python manage.py makemigrations catalog --empty Next open your migration file in your app migrations folder (catalog/migrations) then create a function that will executed by the RunPython() method when you apply your migration 123456789101112131415from django.db import migrationsfrom django.conf import settingsdef create_data(apps, schema_editor): Product = apps.get_model('catalog', 'Product') Product(sku='sku1',name='Product 1', description='Product 1', buyPrice=100 , sellPrice=100,unit='kilogram', quantity=100).save() ##...class Migration(migrations.Migration): dependencies = [ ('catalog', '0001_initial'), ] operations = [ migrations.RunPython(create_data), ] You can then migrate your database to create the initial data 1python manage.py migrate Adding the Serializer ClassFrom Django REST framework docs here is the definition of a serializer Serializers allow complex data such as querysets and model instances to be converted to native Python datatypes that can then be easily rendered into JSON, XML or other content types. Serializers also provide deserialization, allowing parsed data to be converted back into complex types, after first validating the incoming data. Serializers允许将复杂数据（如查询集和模型实例）转换为Python数据类型，然后可以轻松地将其呈现为JSON，XML或其他内容类型。 序列化程序还提供反序列化，允许在首次验证传入数据后将解析后的数据转换回复杂类型。 Create a serializers.py file inside your the catalog app folder then add the following code to create a serializer class for the product model 1234567from rest_framework import serializersfrom .models import Productclass ProductSerializer(serializers.ModelSerializer): class Meta: model = Product fields = ('pk','sku', 'name', 'description', 'buyPrice','sellPrice','unit','quantity') Adding the API ViewsAfter adding the database model and the serializer class and also some seed data the next thing is to create the API views that will be responsible for creating, updating, deleting and fetching data from the database and send it back to users as JSON database when users request the appropriate API endpoint so go ahead and open the catalog/views.py file then start by adding the following imports 123456from rest_framework import statusfrom rest_framework.decorators import api_viewfrom rest_framework.response import Responsefrom django.core.paginator import Paginator, EmptyPage, PageNotAnIntegerfrom .models import Product from .serializers import * This code imports different classes from DRF package, paginator classes to add pagination and then the Product model and its serializer class. Adding the Product List/Create API ViewIn your catalog/views.py add the following view function which can process either GET or POST requests to either return paginated list of products or create a product. 123456789101112131415161718192021222324252627282930313233@api_view(['GET', 'POST'])def product_list(request): """ List products, or create a new product. """ if request.method == 'GET': data = [] nextPage = 1 previousPage = 1 products = Product.objects.all() page = request.GET.get('page', 1) paginator = Paginator(products, 10) try: data = paginator.page(page) except PageNotAnInteger: data = paginator.page(1) except EmptyPage: data = paginator.page(paginator.num_pages) serializer = ProductSerializer(data,context=&#123;'request': request&#125; ,many=True) if data.has_next(): nextPage = data.next_page_number() if data.has_previous(): previousPage = data.previous_page_number() return Response(&#123;'data': serializer.data , 'count': paginator.count, 'numpages' : paginator.num_pages, 'nextlink': '/api/products/?page=' + str(nextPage), 'prevlink': '/api/products/?page=' + str(previousPage)&#125;) elif request.method == 'POST': serializer = ProductSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) This function first checks if it’s a GET or POST request then preforms the processing based on the type of the request: If it’s a GET request, the function retrieves the page number from the GET request or use the first page by default if no page is submitted then retrieves the request page of products, serialize it and return it back alongside with other information such as the next page and previous page links. If it’s a POST request, the function creates the product based on the POST data. Adding the Product Detail API ViewNow you need to add the view function that will be responsible for getting, updating or deleting a single product by id depending on the type of the HTTP request (GET, PUT or DELETE). 123456789101112131415161718192021222324@api_view(['GET', 'PUT', 'DELETE'])def product_detail(request, pk): """ Retrieve, update or delete a product instance. """ try: product = Product.objects.get(pk=pk) except Product.DoesNotExist: return Response(status=status.HTTP_404_NOT_FOUND) if request.method == 'GET': serializer = ProductSerializer(product,context=&#123;'request': request&#125;) return Response(serializer.data) elif request.method == 'PUT': serializer = ProductSerializer(product, data=request.data,context=&#123;'request': request&#125;) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) elif request.method == 'DELETE': product.delete() return Response(status=status.HTTP_204_NO_CONTENT)]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则化方法小结]]></title>
    <url>%2F2018%2F12%2F31%2F%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[在总结正则化（Regularization）之前，我们先谈一谈正则化是什么，为什么要正则化。 个人认为正则化这个字眼有点太过抽象和宽泛，其实正则化的本质很简单，就是对某一问题加以先验的限制或约束以达到某种特定目的的一种手段或操作。在算法中使用正则化的目的是防止模型出现过拟合。一提到正则化，很多同学可能马上会想到常用的L1范数和L2范数，在汇总之前，我们先看下LP范数是什么鬼。 LP范数 范数简单可以理解为用来表征向量空间中的距离，而距离的定义很抽象，只要满足非负、自反、三角不等式就可以称之为距离。 LP范数不是一个范数，而是一组范数，其定义如下： p的范围是[1, +∞],p在(0,1)范围内定义的并不是范数，因为违反了三角不等式。 根据p的变化，范数也有着不同的变化，借用一个经典的有关P范数的变化图如下： 上图表示了p从0到正无穷变化时，单位球（unit ball）的变化情况。在P范数下定义的单位球都是凸集，但是当0&lt;p&lt;1时，该定义下的单位球不是凸集（这个我们之前提过，当0&lt;p&lt;1时并不是范数）。 那问题来了，L0范数是啥玩意？ L0范数表示向量中非零元素的个数，用公式表示如下： 我们可以通过最小化L0范数，来寻找最少最优的稀疏特征项。但不幸的是，L0范数的最优化问题是一个NP hard问题（L0范数同样是非凸的）。因此，在实际应用中我们经常对L0进行凸松弛，理论上有证明，L1范数是L0范数的最优凸近似，因此通常使用L1范数来代替直接优化L0范数。 L1范数 根据LP范数的定义我们可以很轻松的得到L1范数的数学形式： 通过上式可以看到，L1范数就是向量各元素的绝对值之和，也被称为是”稀疏规则算子“（Lasso regularization）。那么问题来了，为什么我们希望稀疏化？稀疏化有很多好处，最直接的两个： 特征选择 可解释性 L2范数 L2范数是我们最熟悉的，它就是欧几里得距离，公式如下： L2范数有很多名称，有人把它的回归叫“岭回归”（Ridge Regression），也有人叫它“权值衰减”（Weight Decay）。以L2范数作为正则项可以得到稠密解，即每个特征对应的参数w都很小，接近于0但是不为0；此外，L2范数作为正则化项，可以防止模型为了迎合训练集而过于复杂造成过拟合的情况，从而提高模型的泛化能力。 L1范数和L2范数的区别 引入PRML一个经典的图来说明下L1和L2范数的区别，如下图所示： 如上图所示，蓝色的圆圈表示问题可能的解范围，橘色的表示正则项可能的解范围。而整个目标函数（原问题+正则项）有解当且仅当两个解范围相切。从上图可以很容易地看出，由于L2范数解范围是圆，所以相切的点有很大可能不在坐标轴上，而由于L1范数是菱形（顶点是凸出来的），其相切的点更可能在坐标轴上，而坐标轴上的点有一个特点，其只有一个坐标分量不为零，其他坐标分量为零，即是稀疏的。所以有如下结论，L1范数可以导致稀疏解，L2范数导致稠密解。 从贝叶斯先验的角度看，当训练一个模型时，仅依靠当前的训练数据集是不够的，为了实现更好的泛化能力，往往需要加入先验项，而加入正则项相当于加入了一种先验。 L1范数相当于加入了一个Laplacean先验； L2范数相当于加入了一个Gaussian先验。 Dropout Dropout是深度学习中经常采用的一种正则化方法。它的做法可以简单的理解为在DNNs训练的过程中以概率p丢弃部分神经元，即使得被丢弃的神经元输出为0。Dropout可以实例化的表示为下图： 我们可以从两个方面去直观地理解Dropout的正则化效果： 在Dropout每一轮训练过程中随机丢失神经元的操作相当于多个DNNs进行取平均，因此用于预测具有vote的效果。 减少神经元之间复杂的共适应性。当隐藏层神经元被随机删除之后，使得全连接网络具有了一定的稀疏化，从而有效地减轻了不同特征的协同效应。也就是说，有些特征可能会依赖于固定关系的隐含节点的共同作用，而通过Dropout的话，就有效地组织了某些特征在其他特征存在下才有效果的情况，增加了神经网络的鲁棒性。 Batch Normalization 批规范化（Batch Normalization）严格意义上讲属于归一化手段，主要用于加速网络的收敛，但也具有一定程度的正则化效果。 这里借鉴下魏秀参博士的知乎回答中对covariate shift的解释。 大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如transfer learning/domain adaptation等。而covariate shift就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同。大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。 BN的基本思想其实相当直观，因为神经网络在做非线性变换前的激活输入值（X = WU + B，U是输入），随着网络深度加深，其分布逐渐发生偏移或者变动（即上述的covariate shift）。之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于Sigmoid函数来说，意味着激活输入值（X = WU + B）是大的负值和正值。所以这导致后向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。而 BN 就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，避免因为激活函数导致的梯度弥散问题。所以与其说BN的作用是缓解covariate shift，倒不如说BN可缓解梯度弥散问题。 归一化、标准化 &amp; 正则化 正则化我们已经提到过了，这里简单提一下归一化和标准化。 归一化（Normalization）：归一化的目标是找到某种映射关系，将原数据映射到[a,b]区间上。一般a，b会取[-1,1]，[0,1]这些组合 。 一般有两种应用场景： 把数变为(0, 1)之间的小数 把有量纲的数转化为无量纲的数 常用Min-Max Normalization： 标准化（Standardization）**：用大数定理将数据转化为一个标准正态分布**，标准化公式为： 归一化和标准化的区别： 我们可以这样简单地解释： 归一化的缩放是“拍扁”统一到区间（仅由极值决定），而标准化的缩放是更加“弹性”和“动态”的，和整体样本的分布有很大的关系。 值得注意： 归一化：缩放仅仅跟最大、最小值的差别有关。 标准化：缩放和每个点都有关系，通过方差（variance）体现出来。与归一化对比，标准化中所有数据点都有贡献（通过均值和标准差造成影响）。 为什么要标准化和归一化？ 提升模型精度：归一化后，不同维度之间的特征在数值上有一定比较性，可以大大提高分类器的准确性。 加速模型收敛：标准化后，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。如下图所示：]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大经典排序算法动画与解析]]></title>
    <url>%2F2018%2F12%2F26%2FSortAlgorithm%2F</url>
    <content type="text"><![CDATA[排序算法是《数据结构与算法》中最基本的算法之一 排序算法可以分为内部排序和外部排序。 内部排序是数据记录在内存中进行排序。 而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。 常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。 用一张图概括： 关于时间复杂度：** 平方阶(O(n2)) 排序 各类简单排序：直接插入、直接选择和冒泡排序。 线性对数阶 (O(nlog2n)) 排序 快速排序、堆排序和归并排序； O(n1+§)) 排序，§ 是介于0 和 1之间的常数。 希尔排序 线性阶(O(n)) 排序 基数排序，此外还有桶、箱排序。 关于稳定性： 稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序。 不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。 1. 冒泡排序1.1 算法步骤 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 1.2 动画演示 1.3 参考代码1234567891011121314void BubbleSort1(int *arr,int sz)&#123; for(int i=0;i&lt;sz-1;i++)&#123; for(int j=0;j&lt;sz-i-1;j++)&#123; if(arr[j]&gt;arr[j+1])&#123; int tmp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = tmp; &#125; &#125; &#125;&#125; 2. 选择排序2.1 算法步骤 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。 2.2 动画演示 2.3 参考代码12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;void SelectSort(int *pData,int size)&#123; for(int i = 0;i&lt;size-1;++i) &#123; int index = i; for(int j = i+1;j&lt;size;++j) &#123; if(pData[j]&lt;pData[index]) index = j; &#125; if(index != i) &#123; int temp = pData[i]; pData[i] = pData[index]; pData[index] = temp; &#125; &#125;&#125;int main()&#123; int pData[10]=&#123;1,5,9,3,4,7,8,2,6,10&#125;; for(int i = 0;i&lt;10;++i) cout&lt;&lt;pData[i]&lt;&lt;' '; cout&lt;&lt;endl; SelectSort(pData,10); for(int i = 0;i&lt;10;++i) cout&lt;&lt;pData[i]&lt;&lt;' '; return 0;&#125; 3. 插入排序3.1 算法步骤 将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 3.2 动画演示 3.3 参考代码123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;void InsertSort(int *a, int n)&#123; for (int j = 1; j &lt; n; j++) &#123; int key = a[j]; //待排序第一个元素 int i = j - 1; //代表已经排过序的元素最后一个索引数 while (i &gt;= 0 &amp;&amp; key &lt; a[i]) &#123; //从后向前逐个比较已经排序过数组，如果比它小，则把后者用前者代替， //其实说白了就是数组逐个后移动一位,为找到合适的位置时候便于Key的插入 a[i + 1] = a[i]; i--; &#125; a[i + 1] = key; //找到合适的位置了，赋值,在i索引的后面设置key值。 &#125;&#125;int main()&#123; int d[] = &#123;12, 15, 9, 20, 6, 31, 24&#125;; cout &lt;&lt; "排序前数组：12, 15, 9, 20, 6, 31, 24, " &lt;&lt; endl; InsertSort(d, 7); cout &lt;&lt; "排序后结果："; for (int i = 0; i &lt; 7; i++) &#123; cout &lt;&lt; d[i] &lt;&lt;","&lt;&lt; " "; &#125; return 0;&#125; 4. 希尔排序4.1 算法步骤 选择一个增量序列 t1，t2，……，tk，其中 ti &gt; tj, tk = 1； 按增量序列个数 k，对序列进行 k 趟排序； 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 4.2 动画演示 4.3 参考代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;int shellSort(int arr[], int n)&#123; // 从一个大的Gap开始， 不断缩小Gao for (int gap = n / 2; gap &gt; 0; gap /= 2) &#123; // 对此间隙大小执行有缺口的插入排序。 // 第一个间隙元素a[0..gap-1]已经是有间隙的顺序 // 继续添加一个元素，直到整个数组都进行了间隙排序 for (int i = gap; i &lt; n; i += 1) &#123; // 在已经进行间隙排序的元素中添加 a[i] // 在temp中保存 a[i] 并在第i个位置留个空隙 int temp = arr[i]; // 移动较早经过Gap-Sort的元素移动直到a[i]的位置被找到 int j; for (j = i; j &gt;= gap &amp;&amp; arr[j - gap] &gt; temp; j -= gap) arr[j] = arr[j - gap]; // 把temp(原来的a[i])放到正确的位置 arr[j] = temp; &#125; &#125; return 0;&#125;void printArray(int arr[], int n)&#123; for (int i = 0; i &lt; n; i++) cout &lt;&lt; arr[i] &lt;&lt; " ";&#125;int main()&#123; int arr[] = &#123;12, 34, 54, 2, 3, 10&#125;, i; //数组长度计算 int n = sizeof(arr) / sizeof(arr[0]); cout &lt;&lt; "排序前的数组: \n"; printArray(arr, n); shellSort(arr, n); cout &lt;&lt; "\n排序后的数组: \n"; printArray(arr, n); return 0;&#125; 5. 归并排序5.1 算法步骤 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针，最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置； 重复步骤 3 直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾。 5.2 动画演示 5.3 参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/* Merge sort in C++ */#include &lt;cstdio&gt;#include &lt;iostream&gt; using namespace std; // Function to Merge Arrays L and R into A.// lefCount = number of elements in L// rightCount = number of elements in R.void Merge(int *A,int *L,int leftCount,int *R,int rightCount) &#123; int i,j,k; // i - to mark the index of left aubarray (L) // j - to mark the index of right sub-raay (R) // k - to mark the index of merged subarray (A) i = 0; j = 0; k =0; while(i&lt;leftCount &amp;&amp; j&lt; rightCount) &#123; if(L[i] &lt; R[j]) A[k++] = L[i++]; else A[k++] = R[j++]; &#125; while(i &lt; leftCount) A[k++] = L[i++]; while(j &lt; rightCount) A[k++] = R[j++];&#125; // Recursive function to sort an array of integers.void MergeSort(int *A,int n) &#123; int mid,i, *L, *R; if(n &lt; 2) return; // base condition. If the array has less than two element, do nothing. mid = n/2; // find the mid index. // create left and right subarrays // mid elements (from index 0 till mid-1) should be part of left sub-array // and (n-mid) elements (from mid to n-1) will be part of right sub-array L = new int[mid]; R = new int [n - mid]; for(i = 0;i&lt;mid;i++) L[i] = A[i]; // creating left subarray for(i = mid;i&lt;n;i++) R[i-mid] = A[i]; // creating right subarray MergeSort(L,mid); // sorting the left subarray MergeSort(R,n-mid); // sorting the right subarray Merge(A,L,mid,R,n-mid); // Merging L and R into A as sorted list. // the delete operations is very important delete [] R; delete [] L;&#125; int main() &#123; /* Code to test the MergeSort function. */ int A[] = &#123;6,2,3,1,9,10,15,13,12,17&#125;; // creating an array of integers. int i,numberOfElements; // finding number of elements in array as size of complete array in bytes divided by size of integer in bytes. // This won't work if array is passed to the function because array // is always passed by reference through a pointer. So sizeOf function will give size of pointer and not the array. // Watch this video to understand this concept - http://www.youtube.com/watch?v=CpjVucvAc3g numberOfElements = sizeof(A)/sizeof(A[0]); // Calling merge sort to sort the array. MergeSort(A,numberOfElements); //printing all elements in the array once its sorted. for(i = 0;i &lt; numberOfElements;i++) cout &lt;&lt; " " &lt;&lt; A[i]; return 0;&#125; 6. 快速排序6.1 算法步骤 从数列中挑出一个元素，称为 “基准”（pivot）; 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序； 6.2 动画演示 6.3 参考代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;iostream&gt;#include &lt;stdio.h&gt;using namespace std;/* low --&gt; Starting index, high --&gt; Ending index */void swap(int *a, int *b)&#123; int t = *a; *a = *b; *b = t;&#125;/* This function takes last element as pivot, places the pivot element at its correct position in sorted array, and places all smaller (smaller than pivot) to left of pivot and all greater elements to right of pivot */int partition(int arr[], int low, int high)&#123; int pivot = arr[high]; // pivot int i = (low - 1); // Index of smaller element for (int j = low; j &lt;= high - 1; j++) &#123; // If current element is smaller than or // equal to pivot if (arr[j] &lt;= pivot) &#123; i++; // increment index of smaller element swap(&amp;arr[i], &amp;arr[j]); &#125; &#125; swap(&amp;arr[i + 1], &amp;arr[high]); return (i + 1);&#125;/* The main function that implements QuickSort arr[] --&gt; Array to be sorted, low --&gt; Starting index, high --&gt; Ending index */void quickSort(int arr[], int low, int high)&#123; if (low &lt; high) &#123; /* pi is partitioning index, arr[p] is now at right place */ int pi = partition(arr, low, high); // Separately sort elements before // partition and after partition quickSort(arr, low, pi - 1); quickSort(arr, pi + 1, high); &#125;&#125;/* Function to print an array */void printArray(int arr[], int size)&#123; int i; for (i = 0; i &lt; size; i++) printf("%d ", arr[i]); printf("\n");&#125;// Driver program to test above functionsint main()&#123; int arr[] = &#123;10, 7, 8, 9, 1, 5&#125;; int n = sizeof(arr) / sizeof(arr[0]); quickSort(arr, 0, n - 1); printf("Sorted array: \n"); printArray(arr, n); return 0;&#125; 7. 堆排序7.1 算法步骤 创建一个堆 H[0……n-1]； 把堆首（最大值）和堆尾互换； 把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置； 重复步骤 2，直到堆的尺寸为 1。 7.2 动画演示 7.3 参考代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;iostream&gt;#include &lt;stdio.h&gt;using namespace std;//辅助交换函数void Swap(int &amp;a, int &amp;b)&#123; int temp = a; a = b; b = temp;&#125;//堆排序的核心是建堆,传入参数为数组，根节点位置，数组长度void Heap_build(int a[], int root, int length)&#123; int lchild = root * 2 + 1; //根节点的左子结点下标 if (lchild &lt; length) //左子结点下标不能超出数组的长度 &#123; int flag = lchild; //flag保存左右节点中最大值的下标 int rchild = lchild + 1; //根节点的右子结点下标 if (rchild &lt; length) //右子结点下标不能超出数组的长度(如果有的话) &#123; if (a[rchild] &gt; a[flag]) //找出左右子结点中的最大值 &#123; flag = rchild; &#125; &#125; if (a[root] &lt; a[flag]) &#123; //交换父结点和比父结点大的最大子节点 Swap(a[root], a[flag]); //从此次最大子节点的那个位置开始递归建堆 Heap_build(a, flag, length); &#125; &#125;&#125;void Heap_sort(int a[], int len)&#123; for (int i = len / 2; i &gt;= 0; --i) //从最后一个非叶子节点的父结点开始建堆 &#123; Heap_build(a, i, len); &#125; for (int j = len - 1; j &gt; 0; --j) //j表示数组此时的长度，因为len长度已经建过了，从len-1开始 &#123; Swap(a[0], a[j]); //交换首尾元素,将最大值交换到数组的最后位置保存 Heap_build(a, 0, j); //去除最后位置的元素重新建堆，此处j表示数组的长度，最后一个位置下标变为len-2 &#125;&#125;int main(int argc, char **argv)&#123; int a[10] = &#123;12, 45, 748, 12, 56, 3, 89, 4, 48, 2&#125;; Heap_sort(a, 10); for (size_t i = 0; i != 10; ++i) &#123; cout &lt;&lt; a[i] &lt;&lt; " "; &#125; cout &lt;&lt; endl; return 0;&#125; 8. 计数排序8.1 算法步骤 花O(n)的时间扫描一下整个序列 A，获取最小值 min 和最大值 max 开辟一块新的空间创建新的数组 B，长度为 ( max - min + 1) 数组 B 中 index 的元素记录的值是 A 中某元素出现的次数 最后输出目标整数序列，具体的逻辑是遍历数组 B，输出相应元素以及对应的个数 8.2 动画演示 8.3 参考代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// C Program for counting sort#include &lt;stdio.h&gt;#include &lt;string.h&gt;#define RANGE 255// The main function that sort the given string arr[] in// alphabatical ordervoid countSort(char arr[])&#123; // The output character array that will have sorted arr char output[strlen(arr)]; // Create a count array to store count of inidividul // characters and initialize count array as 0 int count[RANGE + 1], i; memset(count, 0, sizeof(count)); // Store count of each character for (i = 0; arr[i]; ++i) ++count[arr[i]]; // Change count[i] so that count[i] now contains actual // position of this character in output array for (i = 1; i &lt;= RANGE; ++i) count[i] += count[i - 1]; // Build the output character array for (i = 0; arr[i]; ++i) &#123; output[count[arr[i]] - 1] = arr[i]; --count[arr[i]]; &#125; /* For Stable algorithm for (i = sizeof(arr)-1; i&gt;=0; --i) &#123; output[count[arr[i]]-1] = arr[i]; --count[arr[i]]; &#125; For Logic : See implementation */ // Copy the output array to arr, so that arr now // contains sorted characters for (i = 0; arr[i]; ++i) arr[i] = output[i];&#125;// Driver program to test above functionint main()&#123; char arr[] = "geeksforgeeks"; //"applepp"; countSort(arr); printf("Sorted character array is %sn", arr); return 0;&#125; 9. 桶排序9.1 算法步骤 设置固定数量的空桶。 把数据放到对应的桶中。 对每个不为空的桶中数据进行排序。 拼接不为空的桶中数据，得到结果 桶排序耗用较大的辅助空间，所需要的辅助空间一般与被排序的数列的最大值与最小值有关 9.2 动画演示 9.3 参考代码123456789101112131415161718192021222324252627282930313233343536373839#include &lt;vector&gt;#include &lt;iostream&gt;using namespace std;void bucketSort(vector&lt;int&gt; &amp;vec)&#123; int length = vec.size(); vector&lt;int&gt; buckets(length, 0); //准备一堆桶，容器的下标即待排序数组的键值或键值经过转化后的值 //此时每个桶中都是没有放蛋的，所以都是0 for (int i = 0; i &lt; length; ++i) &#123; buckets[vec[i]]++; //把每个蛋放入到对应的桶中 &#125; int index = 0; for (int i = 0; i &lt; length; ++i) &#123; //把蛋取出，空桶则直接跳过 for (int j = 0; j &lt; buckets[i]; j++) &#123; vec[index++] = i; &#125; &#125;&#125;//上例是直接将键值作为桶下标的程序，没有经过转化int main()&#123; int a[10] = &#123;0, 2, 5, 6, 3, 2, 5, 9, 5, 2&#125;; vector&lt;int&gt; vec(a, a + 10); bucketSort(vec); for (int i = 0; i &lt; vec.size(); ++i) &#123; cout &lt;&lt; vec[i] &lt;&lt; " "; &#125; return 0;&#125; 10. 基数排序10.1 算法步骤 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零 从最低位开始，依次进行一次排序 从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列 10.2 动画演示 10.3 参考代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void countSort(vector&lt;int&gt; &amp;vec, int exp)&#123; //计数排序 vector&lt;int&gt; range(10, 0); int length = vec.size(); vector&lt;int&gt; tmpVec(length, 0); for (int i = 0; i &lt; length; ++i) &#123; range[(vec[i] / exp) % 10]++; &#125; for (int i = 1; i &lt; range.size(); ++i) &#123; range[i] += range[i - 1]; //统计本应该出现的位置 &#125; for (int i = length - 1; i &gt;= 0; --i) &#123; tmpVec[range[(vec[i] / exp) % 10] - 1] = vec[i]; range[(vec[i] / exp) % 10]--; &#125; vec = tmpVec;&#125;void radixSort(vector&lt;int&gt; &amp;vec)&#123; int length = vec.size(); int max = -1; for (int i = 0; i &lt; length; ++i) &#123; //提取出最大值 if (vec[i] &gt; max) max = vec[i]; &#125; //提取每一位并进行比较，位数不足的高位补0 for (int exp = 1; max / exp &gt; 0; exp *= 10) countSort(vec, exp);&#125;int main()&#123; int a[10] = &#123;53, 3, 542, 748, 14, 214, 154, 63, 616, 589&#125;; vector&lt;int&gt; vec(a, a + 10); radixSort(vec); for (int i = 0; i &lt; vec.size(); ++i) &#123; cout &lt;&lt; vec[i] &lt;&lt; " "; &#125; cout &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>Alg</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django流程]]></title>
    <url>%2F2018%2F12%2F04%2FDjango%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[创建项目1Django-admin startproject mysite 注意：路径中不要带有中文 层级目录说明 manage.py 一个命令行工具，可以让我们用多种方式对Django项目进行交互 __init__.py 一个空文件，它告诉Python这个目录应该被看做一个包 settings.py 项目的配置文件（主要处理文件） urls.py 项目的url声明 （主要处理文件） wsgi.py 项目与WSGI兼容的Web服务器入口 配置数据库(mysql) 在Django中，默认使用 SQLite数据库，在settings.py文件中通过DATABASES选项进行数据库配置。 配置mysql 1.在mysite/__init__.py中写入两行代码 12import mysqlmysql.install_as_MySQLdb() 2.在settings.py中对DATABASES进行配置 12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &quot;my_site&quot;, &apos;USER&apos;: &quot;root&quot;, &apos;PASSWORD&apos;: &quot;m&quot;, &apos;HOST&apos;: &quot;localhost&quot;, &apos;PORT&apos;: &quot;3306&quot; &#125;&#125; 创建应用创建 创建应用–在一个项目中可以创建多个应用，每个应用进行一种业务处理在manage.py所在文件夹下打开cmd，输入命令 1python manage.py startapp myapp 层级目录说明 admin.py 进行站点配置，用于注册模型等 models.py 创建模型 views.py 创建视图 test,py 网站测试 migration文件夹 于数据迁移 激活 在settings.py中，将myapo应用加入到INSTALLED.APPS选项中 12345678910INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;myapp&apos;,] 定义模型定义 概述，有一个数据表就对应有一个模型。在models.py中定义模型。模型类要继承models.Model类。所以要import models这个类 示例： 123456789101112131415from django.db import modelsclass Classes(models.Model): cname = models.CharField(max_length=20) cdate = models.DateTimeField() cgirlnum = models.IntegerField() cboynum = models.IntegerField() isDelete = models.BooleanField(default=False)class Students(models.Model): sname = models.CharField(max_length=20) sgender = models.BooleanField(default=True) sage = models.IntegerField() scontend = models.CharField(max_length=20) isDelete = models.BooleanField(default=False) sgrade = models.ForeignKey("Classes", on_delete=models.CASCADE,) 说明：不需要定义主键，在生成时自动添加，并且值为自动增加 迁移 1.生成迁移文件，执行： 1python manage.py makemigrations 2.执行迁移，执行： 1python manage.py migrate 测试数据操作进入到python shell 1python manage.py makemigrations 引入包 123from myApp.models import Grades, Studentsfrom django.utils import timezonefrom datetime import * 查询所有数据 12#类名.objects.all()Student.objects.all() 添加数据 123456789Classes1 = Classes()Classes1.cname = "python"Classes1.cdate = datetime(year=2017, month=7, day=17)Classes1.cgirlnum = 3Classes1.cboynum = 70##保存Classes1.save() 查看某个对象 1234#类名.objects.get(pk=1) pk:primary keyClasses.objects.get(pk=1)#类名.objects.all() 得到所有Classes.objects.get(pk=1) 关联对象 需求获取班所以普学生 12#关联的类名小写_set.all()class.sutdents_set.all() 需求创建A，属于班 1stu3=classes1.students_set.create(**values) 启动服务器格式：python manage.py runserver ip:port Admin站点管理创建管理员用户 在manage.py文件所在目录执行 1python manage.py createsuperuser 一次输入账号、邮箱、密码即可创建用户 登陆 登陆网站： http://localhost:8000/admin/ 汉化 在settings.py中将LANGUAGE_CODE设置为’zh-Hans0’, TIME_ZONE=’Asia/Shanghai’ 管理数据表修改myapp\admin.py: 1234from django.contrib import admin#register your models herefrom .models import Classes, Studentsadmin 自定义管理页面属性说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 列表页属性 list_display = [] # 显示字段设置 list_filter = [] # 过滤字段设置 search_fields = [] # 搜索字段设置 list_per_page = [] # 分页设置 # 添加，修改页属性 fields = [] # 规定属性的先后顺序 fieldsets = [] # 给属性分组 注意：fields与fieldsets不能同时使用 属性示例： # 列表页属性 list_display = ['pk', 'gname', 'gdate', 'ggirlnum', 'gboynum', 'isDelete'] list_filter = ['gname'] search_fields = ['gname'] list_per_page = 5 # 添加，修改页属性 # fields = ['ggirlnum', 'gboynum', 'gname', 'gdate', 'isDelete'] fieldsets = [ ("num",&#123;"fields":['ggirlnum', 'gboynum']&#125;), ("base", &#123;"fields":["gname", "gdate", "isDelete"]&#125;), ] 关联对象：需求：在创建一个班级时可以直接添加几个学生 class StudentsInfo(admin.TabularInline):# 可选参数admin.StackedInline model = Students extra = 2 class GradesAdmin(admin.ModelAdmin): inlines = [StudentsInfo] 布尔值显示问题示例： class StudentsAdmin(admin.ModelAdmin): def gender(self): if self.sgender: return "男" else: return "女" # 设置页面列的名称 gender.short_description = "性别" list_display = ['pk', 'sname', 'sage', gender, 'scontend', 'sgrade', 'isDelete'] list_per_page = 10 admin.site.register(Students, StudentsAdmin) 执行按钮位置： class StudentsAdmin(admin.ModelAdmin): ...snip... actions_on_top = False actions_on_bottom = True admin.site.register(Students, StudentsAdmin) 使用装饰器完成注册： @admin.register(Students) class StudentsAdmin(admin.ModelAdmin): def gender(self): ...snip... actions_on_top = False actions_on_bottom = True 视图的基本使用概述： 在Django中，视图是对web请求进行回应，视图就是一个python函数 流程： 1.网址：Django获取网址信息，去掉端口。 2.虚拟路径与文件名：url管理器逐个匹配urlconf，记录视图函数 3.函数视图名：视图管理，找到对应的视图去执行，返回结果给浏览器 4.相应的数据：返回第一步 重定向错误视图​ 404视图：找不到网页（url匹配不成功时返回） ​ 自定义 404 page： ​ 1.修改project/settings.py 123# SECURITY WARNING: don't run with debug turned on in production!DEBUG = FalseALLOWED_HOSTS = ["*"] 在ALLOWED_HOSTS中设置”*“将允许你在debug中为false时使用任何host婞项目，不要再生产中这样做 设置DEBUG为Flase将会允许你的错误URL返回响应 ​ 2.配置project/urls.py，添加上 12from django.conf.urls import handler404handler404 = 'myapp.views.error_404_view' ​ 3.自定义404错误页面 在/myapp/views.py中写入 123def error_404_view(request, exception): data = &#123;"name": "ThePythonDjango.com"&#125; return render(request,'error_404.html', data) ​ 这样，当用户输入错误的url，我们将会返回project下，templates中的error_404.html页面了 接下来在project/templates文件夹中创建error_404.html 12345678910&lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt; This is a custom 404 error page which will be shown instead of default 404 error page of Django everytime incorrect urls is entered in browser. &lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; urls配置配置流程 1.定制根url配置文件 setting.py中默认实现了 1ROOT_URLCONF = 'project.urls' 2.urlpatterns 在应用中创建urls.py project/urls.py 123456789from django.contrib import adminfrom django.urls import path, includefrom django.conf.urls import handler404, handler500from myapp import urlsurlpatterns = [ path('admin/', admin.site.urls), path('', include('myapp.urls'))]handler404 = 'myapp.views.error_404_view' project/myapp/urls.py 1234567from django.contrib import adminfrom django.urls import path, includefrom . import viewsurlpatterns = [ path('index', views.index), path('&lt;int:a&gt;', views.number),] url反响解析 概述：如果在视图，模板中使用了硬编码链接，在url配置发生改变时，动态生成链接的地址解决：在使用链接时，通过url配置的名称，动态生成url地址作用：使用url模板 视图函数 参数 * 一个Httprequest实例(request), * 从urls中传递过来的参数 HttpRequest 对象 概述： 1234&gt; 服务器接收http请求后，会根据报文创建HttpRequest对象&gt; 视图的第一个参数就是HttpRequest对象&gt; django创建的，之后调用视图时传递给视图&gt; 属性 path:请求的完整路径（不包括域名和端口） method:表示请求的方式，常用的有GET,POST encoding:表示浏览器提交的数据的编码方式，一般为utf-8 GET：类似于字典的对象，包含了get请求的所有参数 POST:类似于字典的对象，包含了post请求的所有参数 FILES:类似字典的对象，包含了所有上传的文件 COOKIES:字典，包含所有的cookie session:类似字典的对象，表示当前会话 方法和对象 is_ajax():如果是通过XMLHttpRequest发起的，返回 True]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tf.strided_slice]]></title>
    <url>%2F2018%2F11%2F27%2Ftf-strided-slice%2F</url>
    <content type="text"><![CDATA[tf.strided_slice其实就是TensorFlow中用来分片的函数。 1234567891011def strided_slice(input_, begin, end, strides=None, begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0, var=None, name=None): begin是分片开始， end是分片结束，strides是步长，注意这边的步长其实是从步长的最后一位开始的 Question：I am wondering what tf.strided_slice() operator actually does.The doc says, To a first order, this operation extracts a slice of size end - begin from a tensor input starting at the location specified by begin. The slice continues by adding stride to the begin index until all dimensions are not less than end. Note that components of stride can be negative, which causes a reverse slice. And in the sample, 12345678# 'input' is [[[1, 1, 1], [2, 2, 2]],# [[3, 3, 3], [4, 4, 4]],# [[5, 5, 5], [6, 6, 6]]]tf.slice(input, [1, 0, 0], [2, 1, 3], [1, 1, 1]) ==&gt; [[[3, 3, 3]]]tf.slice(input, [1, 0, 0], [2, 2, 3], [1, 1, 1]) ==&gt; [[[3, 3, 3], [4, 4, 4]]]tf.slice(input, [1, 1, 0], [2, -1, 3], [1, -1, 1]) ==&gt;[[[4, 4, 4], [3, 3, 3]]] So in my understanding of the doc, the first sample (tf.slice(input, begin=[1, 0, 0], end=[2, 1, 3], strides=[1, 1, 1])), resulting size is end - begin = [1, 1, 3]. The sample result shows [[[3, 3, 3,]]], that shape is [1, 1, 3], it seems OK. the first element of the result is at begin = [1, 0, 0]. The first element of the sample result is 3, which is input[1,0,0], it seems OK. the slice continues by adding stride to the begin index. So the second element of the result should be input[begin + strides] = input[2, 1, 1] = 6, but the sample shows the second element is 3. What strided_slice() does? AnswerThe mistake in your argument is the fact that you are directly adding the lists strides and beginelement by element. This will make the function a lot less useful. Instead, it increments the beginlist one dimension at a time, starting from the last dimension. Let’s solve the first example part by part. begin = [1, 0, 0] and end = [2, 1, 3]. Also, all the strides are 1. Work your way backwards, from the last dimension. Start with element [1,0,0]. Now increase the last dimension only by its stride amount, giving you [1,0,1]. Keep doing this until you reach the limit. Something like [1,0,2], [1,0,3] (end of the loop). Now in your next iteration, start by incrementing the second to last dimension and resetting the last dimension, [1,1,0]. Here the second to last dimension is equal to end[1], so move to the first dimension (third to last) and reset the rest, giving you [2,0,0]. Again you are at the first dimension’s limit, so quit the loop. The following code is a recursive implementation of what I described above, 12345678910111213# Assume global `begin`, `end` and `stride`def iterate(active, dim): if dim == len(begin): # last dimension incremented, work on the new matrix # Note that `active` and `begin` are lists new_matrix[active - begin] = old_matrix[active] else: for i in range(begin[dim], end[dim], stride[dim]): new_active = copy(active) new_active[dim] = i iterate(new_active, dim + 1)iterate(begin, 0)]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML5]]></title>
    <url>%2F2018%2F11%2F22%2Fhtml5%2F</url>
    <content type="text"><![CDATA[HTML Attributes Attribute Description alt Specifies an alternative text for an image, when the image cannot be displayed 图片无法显示时候提示是怎么样的图片 disabled Specifies that an input element should be disabled href Specifies the URL (web address) for a link id Specifies a unique id for an element src Specifies the URL (web address) for an image 也就是图片的source style Specifies an inline CSS style for an element title Specifies extra information about an element (displayed as a tool tip) 鼠标停留时显示的字样 width, height 图片的宽和高 HTML Horizontal Rules 标签水平The &lt;hr&gt; tag defines a thematic break in an HTML page, and is most often displayed as a horizontal rule. The &lt;hr&gt; element is used to separate content (or define a change) in an HTML page: 123456&lt;h1&gt;This is heading 1&lt;/h1&gt;&lt;p&gt;This is some text.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;This is heading 2&lt;/h2&gt;&lt;p&gt;This is some other text.&lt;/p&gt;&lt;hr&gt; This is heading 1This is some text. This is heading 2This is some other text. This is heading 2This is some other text. Bigger Headings 更大的标题Each HTML heading has a default size. However, you can specify the size for any heading with the style attribute, using the CSS font-size property: 也就是说h1, h2, h3这些的字体大小都是可以调整的 1&lt;h1 style=&quot;font-size:60px;&quot;&gt;Heading 1&lt;/h1&gt; The HTML &lt;pre&gt; Element 标签实例预格式化的文本The HTML &lt;pre&gt; element defines preformatted text. The text inside a &lt;pre&gt; element is displayed in a fixed-width font (usually Courier), and it preserves both spaces and line breaks: 会保留文本原格式 Tag Description p Defines a paragraph br Inserts a single line break pre Defines pre-formatted text Style Chapter Summary Use the style attribute for styling HTML elements Use background-color for background color Use color for text colors Use font-family for text fonts Use font-size for text sizes Use text-align for text alignment HTML Formatting &lt;b&gt; - Bold text &lt;strong&gt; - Important text &lt;i&gt; - Italic text &lt;em&gt; - Emphasized text &lt;mark&gt; - Marked text &lt;small&gt; - Small text &lt;del&gt; - Deleted text &lt;ins&gt; - Inserted text &lt;sub&gt; - Subscript text &lt;sup&gt; - Superscript text mark &lt;mark&gt; ​ del &lt;del&gt; ​ insert &lt;ins&gt; small &lt;small&gt; ​ ​ subscripted &lt;sub&gt; ​ superscripted &lt;sup&gt; HTML Quotation and Citation ElementsHTML &lt;blockquote&gt; for QuotationsThe HTML &lt;blockquote&gt; element defines a section that is quoted from another source. Browsers usually indent &lt;blockquote&gt; elements. （块状引用） The HTML &lt;abbr&gt; element defines an abbreviation or an acronym.（缩写简称 如：WHO是World Health Organization） The HTML &lt;address&gt; element defines contact information (author/owner) of a document or an article. The &lt;address&gt; element is usually displayed in italic. Most browsers will add a line break before and after the element. Tag Description abbr Defines an abbreviation or acronym address Defines contact information for the author/owner of a document bdo Defines the text direction blockquote Defines a section that is quoted from another source cite Defines the title of a work q Defines a short inline quotation The HTML &lt;meta&gt; ElementThe &lt;meta&gt; element is used to specify which character set is used, page description, keywords, author, and other metadata. Metadata is used by browsers (how to display content), by search engines (keywords), and other web services. Define the character set used: The HTML &lt;base&gt; ElementThe &lt;base&gt; element specifies the base URL and base target for all relative URLs in a page: CSS FloatsIt is common to do entire web layouts using the CSS float property. Float is easy to learn - you just need to remember how the float and clear properties work.Disadvantages: Floating elements are tied to the document flow, which may harm the flexibility. Learn more about float in our CSS Float and Clear chapter. CSS FlexboxFlexbox is a new layout mode in CSS3. Use of flexbox ensures that elements behave predictably when the page layout must accommodate different screen sizes and different display devices. Disadvantages:Does not work in IE10 and earlier. Learn more about flexbox in our CSS Flexbox chapter. Attribute Description accept-charset Specifies the charset used in the submitted form (default: the page charset). action Specifies an address (url) where to submit the form (default: the submitting page). autocomplete Specifies if the browser should autocomplete the form (default: on). enctype Specifies the encoding of the submitted data (default: is url-encoded). method Specifies the HTTP method used when submitting the form (default: GET). name Specifies a name used to identify the form (for DOM usage: document.forms.name). novalidate Specifies that the browser should not validate the form. target Specifies the target of the address in the action attribute (default: _self). The &lt;select&gt; ElementThe &lt;select&gt; element defines a drop-down list: 123456&lt;select name="cars"&gt; &lt;option value="volvo"&gt;Volvo&lt;/option&gt; &lt;option value="saab"&gt;Saab&lt;/option&gt; &lt;option value="fiat"&gt;Fiat&lt;/option&gt; &lt;option value="audi"&gt;Audi&lt;/option&gt;&lt;/select&gt; Volvo Saab Fiat Audi Allow Multiple Selections:Use the multiple attribute to allow the user to select more than one value: 123456&lt;select name="cars" size="4" multiple&gt; &lt;option value="volvo"&gt;Volvo&lt;/option&gt; &lt;option value="saab"&gt;Saab&lt;/option&gt; &lt;option value="fiat"&gt;Fiat&lt;/option&gt; &lt;option value="audi"&gt;Audi&lt;/option&gt;&lt;/select&gt; Volvo Saab Fiat Audi The &lt;textarea&gt; ElementThe &lt;textarea&gt; element defines a multi-line input field (a text area): HTML5 &lt;datalist&gt;ElementThe &lt;datalist&gt; element specifies a list of pre-defined options for an &lt;input&gt; element. Users will see a drop-down list of the pre-defined options as they input data. The list attribute of the &lt;input&gt; element, must refer to the id attribute of the &lt;datalist&gt; element. 12345678910&lt;form action="/action_page.php"&gt; &lt;input list="browsers"&gt; &lt;datalist id="browsers"&gt; &lt;option value="Internet Explorer"&gt; &lt;option value="Firefox"&gt; &lt;option value="Chrome"&gt; &lt;option value="Opera"&gt; &lt;option value="Safari"&gt; &lt;/datalist&gt; &lt;/form&gt; HTML5 &lt;output&gt;ElementThe &lt;output&gt; element represents the result of a calculation (like one performed by a script). 1234567891011&lt;form action=&quot;/action_page.php&quot; oninput=&quot;x.value=parseInt(a.value)+parseInt(b.value)&quot;&gt; 0 &lt;input type=&quot;range&quot; id=&quot;a&quot; name=&quot;a&quot; value=&quot;50&quot;&gt; 100 + &lt;input type=&quot;number&quot; id=&quot;b&quot; name=&quot;b&quot; value=&quot;50&quot;&gt; = &lt;output name=&quot;x&quot; for=&quot;a b&quot;&gt;&lt;/output&gt; &lt;br&gt;&lt;br&gt; &lt;input type=&quot;submit&quot;&gt;&lt;/form&gt; 0 100 + = Input Type Password&lt;input type=&quot;password&quot;&gt; defines a password field: 123456&lt;form&gt; User name:&lt;br&gt; &lt;input type="text" name="username"&gt;&lt;br&gt; User password:&lt;br&gt; &lt;input type="password" name="psw"&gt;&lt;/form&gt; User name: User password: Input Type Checkbox&lt;input type=&quot;checkbox&quot;&gt; defines a checkbox. Checkboxes let a user select ZERO or MORE options of a limited number of choices. I have a bike I have a car Input Type ColorThe &lt;input type=&quot;color&quot;&gt; is used for input fields that should contain a color. Depending on browser support, a color picker can show up in the input field. Select your favorite color: Input Type DateThe &lt;input type=&quot;date&quot;&gt; is used for input fields that should contain a date. Depending on browser support, a date picker can show up in the input field. Birthday: You can also use the min and max attributes to add restrictions to dates: 123456&lt;form&gt; Enter a date before 1980-01-01: &lt;input type="date" name="bday" max="1979-12-31"&gt;&lt;br&gt; Enter a date after 2000-01-01: &lt;input type="date" name="bday" min="2000-01-02"&gt;&lt;br&gt;&lt;/form&gt; Enter a date before 1980-01-01: Enter a date after 2000-01-01: Input Type Datetime-localThe &lt;input type=&quot;datetime-local&quot;&gt; specifies a date and time input field, with no time zone. Depending on browser support, a date picker can show up in the input field. Input Type EmailThe &lt;input type=&quot;email&quot;&gt; is used for input fields that should contain an e-mail address. Depending on browser support, the e-mail address can be automatically validated when submitted. Some smartphones recognize the email type, and adds “.com” to the keyboard to match email input. 1234&lt;form&gt; E-mail: &lt;input type="email" name="email"&gt;&lt;/form&gt; E-mail: The readonly AttributeThe readonly attribute specifies that the input field is read only (cannot be changed): 1234&lt;form action=""&gt; First name:&lt;br&gt; &lt;input type="text" name="firstname" value="John" readonly&gt;&lt;/form&gt; First name: The disabled AttributeThe disabled attribute specifies that the input field is disabled. A disabled input field is unusable and un-clickable, and its value will not be sent when submitting the form: First name: The size AttributeThe size attribute specifies the size (in characters) for the input field: 1234&lt;form action=""&gt; First name:&lt;br&gt; &lt;input type="text" name="firstname" value="John" size="40"&gt;&lt;/form&gt; First name: The maxlength AttributeThe maxlength attribute specifies the maximum allowed length for the input field: The autocomplete AttributeThe autocomplete attribute specifies whether a form or input field should have autocomplete on or off. When autocomplete is on, the browser automatically completes the input values based on values that the user has entered before. Tip: It is possible to have autocomplete “on” for the form, and “off” for specific input fields, or vice versa. The autocomplete attribute works with &lt;form&gt; and the following &lt;input&gt; types: text, search, url, tel, email, password, datepickers, range, and color. The novalidate AttributeThe novalidate attribute is a &lt;form&gt; attribute. When present, novalidate specifies that the form data should not be validated when submitted. The autofocus AttributeThe autofocus attribute specifies that the input field should automatically get focus when the page loads. 1First name:&lt;input type="text" name="fname" autofocus&gt; The form AttributeThe form attribute specifies one or more forms an &lt;input&gt; element belongs to. Tip: To refer to more than one form, use a space-separated list of form ids. 123456&lt;form action="/action_page.php" id="form1"&gt; First name: &lt;input type="text" name="fname"&gt;&lt;br&gt; &lt;input type="submit" value="Submit"&gt;&lt;/form&gt;Last name: &lt;input type="text" name="lname" form="form1"&gt; The formenctype AttributeThe formenctype attribute specifies how the form data should be encoded when submitted (only for forms with method=”post”). The formenctype attribute overrides the enctype attribute of the &lt;form&gt; element. The formenctype attribute is used with type=&quot;submit&quot; and type=&quot;image&quot;. The formmethod AttributeThe formmethod attribute defines the HTTP method for sending form-data to the action URL. The formmethod attribute overrides the method attribute of the &lt;form&gt; element. The formmethod attribute can be used with type=&quot;submit&quot; and type=&quot;image&quot;. The formnovalidate AttributeThe formnovalidate attribute overrides the novalidate attribute of the &lt;form&gt; element. The formnovalidate attribute can be used with type=&quot;submit&quot;. The formtarget AttributeThe formtarget attribute specifies a name or a keyword that indicates where to display the response that is received after submitting the form. The formtarget attribute overrides the target attribute of the &lt;form&gt; element. The formtarget attribute can be used with type=&quot;submit&quot; and type=&quot;image&quot;. The multiple AttributeThe multiple attribute specifies that the user is allowed to enter more than one value in the &lt;input&gt; element. The multiple attribute works with the following input types: email, and file. The pattern Attribute正则表达式The pattern attribute specifies a regular expression that the &lt;input&gt; element’s value is checked against. The pattern attribute works with the following input types: text, search, url, tel, email, and password. Tip: Use the global title attribute to describe the pattern to help the user. Tip: Learn more about regular expressions in our JavaScript tutorial. The placeholder AttributesThe placeholder attribute specifies a hint that describes the expected value of an input field (a sample value or a short description of the format). The hint is displayed in the input field before the user enters a value. The placeholder attribute works with the following input types: text, search, url, tel, email, and password. The placeholder Attribute (HINT )The placeholder attribute specifies a hint that describes the expected value of an input field (a sample value or a short description of the format). The hint is displayed in the input field before the user enters a value. The placeholder attribute works with the following input types: text, search, url, tel, email, and password. &lt;!DOCTYPE html&gt; L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":80,"height":200},"mobile":{"show":false},"log":false}); The placeholder Attribute The placeholder attribute specifies a hint that describes the expected value of an input field (a sample value or a short description of the format).]]></content>
      <categories>
        <category>HTML</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[leetcode_5]]></title>
    <url>%2F2018%2F11%2F15%2Fleetcode_5%2F</url>
    <content type="text"><![CDATA[[LeetCode: No.5] Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: 123Input: &quot;babad&quot;Output: &quot;bab&quot;Note: &quot;aba&quot; is also a valid answer. Example 2: 12Input: &quot;cbbd&quot;Output: &quot;bb&quot; 最长回文子串的中间子串也是回文串，换言之，回文串是否最长，可以看回文串两边的字符是否相同。例如“dabcba”的最长回文子串是“abcba”，其可看出回文子串“bcb”的拓展，判断“bab”两边的字符是否相同决定是否进行回文子串拓展（可以利用切片的索引左右移动实现） 由这个想法下， 写出第一个代码： 1234567891011121314151617class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ if len(s) &lt; 2: return s self.res = "" for i in range(len(s)): left = right = i while left&gt;=0 and right &lt; len(s) and s[left] == s[right]: left -= 1 right += 1 if right -left -1 &gt; len(self.res): self.res = s[left+1:right] return self.res 其中在While语句中， s[left] == s[right]是一定要放在最后面的，因为在python中and的机制是这样的and之前的是Flase， 那么and后面的就不会被执行，有可能会出现left=-1或者right=len(s)，这是的s[left]和s[right]会超出索引值。还有就是一定要注意字符串的索引值和长度。 但是这段代码还是会出错，当输出值s为’abbc’是 ，检测不出bb，因为他没有对称中心。所以我们在做添加，left和right的初始值不设为想等而是相差1 1234567891011121314151617181920212223class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ if len(s) &lt; 2: return s self.res = "" for i in range(len(s)): #这里就是考虑到两种情况，从相同字符拓宽和从相邻字符拓宽 self.helper(s, i, i) self.helper(s, i, i+1) return self.res def helper(self,s, left, right): #这里是判断当前回文子串两端相同的时候，向两端拓展 while left&gt;=0 and right &lt; len(s) and s[left] == s[right]: left -= 1 right += 1 #这里的right-left-1是当前的回文子串长度，大于历史最大值，就更新最大值 if right -left -1 &gt; len(self.res): self.res = s[left+1:right]]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode_4]]></title>
    <url>%2F2018%2F11%2F13%2Fleetcode_4%2F</url>
    <content type="text"><![CDATA[[LeetCode: No.4] There are two sorted arrays nums1 and nums2 of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). You may assume nums1 and nums2 cannot be both empty. 仔细分析题目，nums1和nums2都已经是排好序了的，这就大大的降低了难度，让找到两个列表的中间值，其实我们可以拓展为找到两个列表的第k个值。当然这个是拓展部分了，对于这个题目，有不同的思路，最简单粗暴的就是将两个列表合并，之后进行排序，拍好序后进行寻找中间值就简单了。但是用传统的先合并再排序，效率想必会很低~ 我们发现对于两个已经有序的列表（从小到大），其实有一个更优的排序方式：从小到大，依次进行列表元素的比较，较小值放到一个新列表中，比如A中该位置的值较小，将其放到新的列表C中，同时将A列表下一个值继续与B中当前位置元素进行比较，以此类推。这样的比较次数就比先合并在排序小很多啦！代码如下： 1234567891011121314151617181920212223242526272829303132class Solution: def findMedianSortedArrays(self, nums1, nums2): """ :type nums1: List[int] :type nums2: List[int] :rtype: float """ length = len(nums1)+len(nums2) #计算总长度 num = [0] * length index, i_1, i_2 = 0 #当输入两个列表都还存在元素没进行比较的时候，循环进行对比 #并将较小值放入新列表，同时较小元素的列表和新列表索引加一 while i_1&lt;len(nums1) and i_2 &lt; len(nums2): if nums1[i_1] &gt;= nums2[i_2]: num[index] = nums2[i_2] i_2 += 1 else: num[index] = nums1[i_1] i_1 += 1 index += 1 #当存在某一个列表所有元素已经比较完，即排好了序 #剩下那个列表剩下的值直接放入新列表对应位置即可 if i_1 == len(nums1) : #这里要注意的是， 我们while语句最后都多加了一个1所以这里是==len(nums1) num[index:] = nums2[i_2:] else: num[index:] = nums1[i_1:] if length % 2 == 0: return float(num[length//2]+num[length//2 - 1])/2 else: return num[length//2]]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python妹子爬虫（1）]]></title>
    <url>%2F2018%2F11%2F12%2Fpython%E5%A6%B9%E5%AD%90%E7%88%AC%E8%99%AB(1)%2F</url>
    <content type="text"><![CDATA[这篇博客写一个python妹子爬虫(嘿嘿嘿) 我们要爬取的网站是http://www.doyo.cn/tu ，网页是这样的： 可以看到，好多美女的。 我们点开其中一个连接，进入其页面，是哇小姐姐真漂亮^^，同时我们发现链接地址地址为http://www.doyo.cn/picture/7399 ，也就是说我们只要知道/picure/后面的数字就可以找到这个小姐姐了！~ 思路 大体的思路很简单，就是先爬取每一个小姐姐的连接，然后由每个分类爬取这个小姐姐的所有图片。 导入库1234567import randomimport timeimport requestsfrom requests.exceptions import RequestExceptionimport jsonimport osimport re 爬取分类的连接 第一步就是获得分类连接，我们在首页打开Chrome的审查，点开Network选项， 发现在Ajax请求返回了一个Json格式的数据，其中包括了每个小姐姐的信息，其中就有这个小姐姐的网页连接 注意到这第七项的7276就是这个小姐姐的连接的后缀了。 这个Ajax的连接是http://www.doyo.cn/tu/getdata?cate=all&amp;tag=all&amp;sort=updatetime&amp;start=50&amp;count=25 ，也就是说我们只要设置其中的start参数就可以无限的得到这些包含小姐姐信息的Json文件连接了。 由此引出第一个函数： 12345678910111213141516data_url = 'http://www.doyo.cn/tu/getdata'def get_one_page(start): params = &#123; "cate": "all", "tag": "all", "sort": "updatetime", "start": start, "count": 25 &#125; try: response = requests.get(url=data_url, params=params) if response.status_code == 200: return response.text return None except RequestException: print("NetWork Error") 其中我们传入的参数是start，这里的data_url就是Ajax亲贵根网页。构造一个params字典作为参数然后用requests.get请求网页，我们通过我们传入的params，requests将会自动给我们构建出url连接，如果请求失败，我们设置except，自动抛出”Network Error” 解析Ajax请求返回的Json文本 由上一个函数返回值是一个文本，大概是这个样子的 它的本质是一个Json格式的字典，就是前面图片 我们定义一个函数，用json解析文档，其中的number是指小姐姐地址的后缀，count是指小姐姐有几张图片，等下我们会用这两个来构建图片的网址： 12345678910def get_one_data(html): data = json.loads(html) if data and 'info' in data.keys(): for info in data.get('info'): yield &#123; 'title': info[0], 'count': info[1], 'pic': info[6], 'number': info[7] &#125; 如果data字典中不是None并且字典中有‘info’我们对info中的值进行操作。这个键值我们yield返回一个生成器，生成器每次都会迭代出一个json格式的文本 解析每个json文本，得到链接列表 上一个函数中返回的是一个生成器，每次迭代都会返回json文本，接下来我们就需要根据每每个json文本得到图片的地址了每张小姐姐图片的地址是http://www.doyo.cn/picture/{number}/{index}/viewhttp://www.doyo.cn/picture/{number}/{index}/view ，其中number是小姐姐的编号，index就是某个小姐姐的所有图片中的某一张的编号了我们用一个for语句来得到每张图片。然后yield出所有的地址 12345root_url = 'http://www.doyo.cn/picture/&#123;number&#125;/&#123;index&#125;/view'def get_img_urllist(res): # root_url = 'http://www.doyo.cn/picture/&#123;number&#125;/&#123;index&#125;/view' for index in range(1, int(res.get('count')) + 1): yield root_url.format(number=res.get('number'), index=index) 解析每个链接，得到每一张图片链接 经过上一步得到的图片列表，其中每一个连接的页面将会是这样： 用正则表达式匹配图片的链接，先写正则表达式： 1pattern = re.compile('&lt;img src="(.*?)" id="big_picture" /&gt;', re.S) 然后进行匹配： 123456def get_img_url(imag_url): print('image_url' , imag_url) html = get_html(imag_url) res = re.search(pattern=pattern, string=html) if res: return res.group(1) 123456789def get_html(url): try: response = requests.get(url, headers=headers) if response.status_code == 200: return response.text else: return None except RequestException: print("connection error") 返回链接。 保存图片1234567891011121314151617181920def save_img(res): os.chdir(parent_path) try: os.mkdir(res.get('title')) os.chdir(res.get('title')) except: pass url_list = get_img_urllist(res) for imag_url in url_list: url = get_img_url(imag_url) print(imag_url) try: filename = str(random.random()) time.sleep(0.1) response = requests.get(url, headers=headers) with open(filename + '.jpg', 'wb') as f: f.write(response.content) except: pass 这里我们保存图片时，每个小姐姐都新建一个文件夹存入 main函数12345678910111213141516def main(start): html = get_one_page(start) res = get_one_data(html) for each in res: print(each) write_to_file(each) save_img(each)if __name__ == '__main__': start = [n * 25 for n in range(0, 1)] for i in start: main(i) j.close() 开始爬取]]></content>
      <categories>
        <category>Python爬虫</category>
      </categories>
      <tags>
        <tag>Python爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于TensorFlow的验证码识别]]></title>
    <url>%2F2018%2F11%2F11%2F%E5%9F%BA%E4%BA%8ETensorFlow%E7%9A%84%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[这篇博客我们来用TensorFlow来实现一个验证码识别的深度学习模型，我们的。我们会先用标注好的数据来训练第一个模型，然后再用模型来实现验证码识别 验证码 我们先看下验证码是怎么样的， 我们使用Python的captcha库来生成验证码，再用pip安装好captcha之后，就可以用代码来生成一个简单的图形验证码了。1234567891011from captcha.image import ImageCaptchafrom PIL import Imagefrom matplotlib import pyplot as plttext = '1234'image = ImageCaptcha()captcha = image.generate(text)captcha_image = Image.open(captcha)plt.figure()plt.imshow(captcha_image) 运行代码，就可以看到这样的图片了： 可以看到图片中的验证码内容就是我们所定义的text内容，这样我们就可以得到一张图片和其所对应的真是文本你，由此我们用它生成一批训练数据和测试数据 生成数据我们先定义一个词表和其长度变量 123VOCAB = list(str(123456789))CAPTCHA_LENGTH = 4VOCAB_LENGTH = len(VOCAB) 这里 VOCAB 就是词表的内容，即 0 到 9 这 10 个数字，验证码的字符个数即 CAPTCHA_LENGTH 是 4，词表长度是 VOCAB 的长度，即 10。 接下来我们定义一个生成验证码数据的方法，流程类似上文，只不过这里我们利用np.asarray()方法将返回的数据转为了 Numpy 形式的数组： 123456def generate_captcha(captcha_text): image = ImageCaptcha() captcha = image.generate(captcha_text) captcha_image = Image.open(captcha) captcha_array = np.asarray(captcha_image) return captcha_array 我们看一下生成的验证码的矩阵shape是(60, 160, 3),是 60 x 160 像素的验证码，每个像素都有 RGB 值，所以最后一维即为像素的 RGB 值。 接下来我们需要定义 label，由于我们需要使用深度学习模型进行训练，所以这里我们的 label 数据最好使用 One-Hot 编码，即如果验证码文本是 1234，那么应该词表索引位置置 1，总共的长度是 40，我们用程序实现一下 One-Hot 编码和文本的互相转换。即如果验证码文本是 1234，那么应该词表索引位置置 1，总共的长度是 40 one-hot编码将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。one-hot多应用于分类器中。 将离散型特征使用one-hot编码，确实会让特征之间的距离计算更加合理。比如，有一个离散型特征，代表工作类型，该离散型特征，共有三个取值，不使用one-hot编码，其表示分别是x_1 = (1), x_2 = (2), x_3 = (3)。两个工作之间的距离是，(x_1, x_2) = 1, d(x_2, x_3) = 1, d(x_1, x_3) = 2。那么x_1和x_3工作之间就越不相似吗？显然这样的表示，计算出来的特征的距离是不合理。那如果使用one-hot编码，则得到x_1 = (1, 0, 0), x_2 = (0, 1, 0), x_3 = (0, 0, 1)，那么两个工作之间的距离就都是sqrt(2).即每两个工作之间的距离是一样的，显得更合理。 我们用程序实现一下one-hot编码和文本的互相转化 1234567891011121314151617181920def text2vec(text): if len(text) &gt; CAPTCHA_LENGTH: return False vector = np.zeros(CAPTCHA_LENGTH * VOCAB_LENGTH) for i, c in enumerate(text): index = i * VOCAB_LENGTH + VOCAB.index(c) vector[index] = 1 return vector def vec2text(vector): if not isinstance(vector, np.ndarray): vector = np.asarray(vector) vector = np.reshape(vector, [CAPTCHA_LENGTH, -1]) #这边的reshape的-1是将会被自动填入np的总长度除以CAPTCHA_LENGTH text = '' for item in vector: text += VOCAB[np.argmax(item)] return text 接下来我们构造出一批数据， x数据就是验证码的Numpy数组，y数据就是验证码文本的on-hot编码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import randomfrom os.path import join, existsimport pickleimport numpy as npfrom os import makedirsDATA_LENGTH = 10000DATA_PATH = 'data'def get_random_text(): text = '' for i in range(CAPTCHA_LENGTH): text += random.choice(VOCAB) return textdef generate_data(): print('Generating Data...') data_x, data_y = [], [] # generate data x and y for i in range(DATA_LENGTH): text = get_random_text() # get captcha array captcha_array = generate_captcha(text) # get vector vector = text2vec(text) data_x.append(captcha_array) data_y.append(vector) # write data to pickle if not exists(DATA_PATH): makedirs(DATA_PATH) x = np.asarray(data_x, np.float32) y = np.asarray(data_y, np.float32) with open(join(DATA_PATH, 'data.pkl'), 'wb') as f: pickle.dump(x, f) pickle.dump(y, f)import randomfrom os.path import join, existsimport pickleimport numpy as npfrom os import makedirs DATA_LENGTH = 10000DATA_PATH = 'data' def get_random_text(): text = '' for i in range(CAPTCHA_LENGTH): text += random.choice(VOCAB) return text def generate_data(): print('Generating Data...') data_x, data_y = [], [] # generate data x and y for i in range(DATA_LENGTH): text = get_random_text() # get captcha array captcha_array = generate_captcha(text) # get vector vector = text2vec(text) data_x.append(captcha_array) data_y.append(vector) # write data to pickle if not exists(DATA_PATH): makedirs(DATA_PATH) x = np.asarray(data_x, np.float32) y = np.asarray(data_y, np.float32) with open(join(DATA_PATH, 'data.pkl'), 'wb') as f: pickle.dump(x, f) pickle.dump(y, f) 定义一个get_random_text()函数， 用于随机生成验证码文本， 然后用pickle写进硬盘。完成了生成数据的工作。 构建模型 我们用pickle.loads导入数据 ，从sklearn.model_selection 导入 train_test_split方法将模型分为三部分，训练集开发集，验证集，(比例为6：2：2): 1234567891011121314with open('data.pkl', 'rb') as f: data_x = pickle.load(f) data_y = pickle.load(f) return standardize(data_x), data_ytrain_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.4, random_state=40)dev_x, test_x, dev_y, test_y, = train_test_split(test_x, test_y, test_size=0.5, random_state=40)with open('data.pkl', 'rb') as f: data_x = pickle.load(f) data_y = pickle.load(f) return standardize(data_x), data_y train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.4, random_state=40)dev_x, test_x, dev_y, test_y, = train_test_split(test_x, test_y, test_size=0.5, random_state=40) 接下来我们使用者三个数据集构建三个 Dataset 对象, 关于Tensorflow中的数据导入，可以参考Google官方文档 123456789# train and dev datasettrain_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(10000)train_dataset = train_dataset.batch(FLAGS.train_batch_size) dev_dataset = tf.data.Dataset.from_tensor_slices((dev_x, dev_y))dev_dataset = dev_dataset.batch(FLAGS.dev_batch_size) test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))test_dataset = test_dataset.batch(FLAGS.test_batch_size) tf.data.Dataset 表示一系列元素，其中每个元素包含一个或多个 Tensor 对象。例如，在图片管道中，元素可能是单个训练样本，具有一对表示图片数据和标签的张量。可以通过两种不同的方式来创建数据集： 创建来源（例如 Dataset.from_tensor_slices()），以通过一个或多个 tf.Tensor 对象构建数据集。 应用转换（例如 Dataset.batch()），以通过一个或多个 tf.data.Dataset 对象构建数据集。 然后我们初始化一个迭代器，并绑定到这个数据集上： 12345# a reinitializable iteratoriterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)train_initializer = iterator.make_initializer(train_dataset)dev_initializer = iterator.make_initializer(dev_dataset)test_initializer = iterator.make_initializer(test_dataset) tf.data.Iterator 提供了从数据集中提取元素的主要方法。Iterator.get_next() 返回的操作会在执行时生成 Dataset 的下一个元素，并且此操作通常充当输入管道代码和模型之间的接口。最简单的迭代器是“单次迭代器”，它与特定的 Dataset 相关联，并对其进行一次迭代。要实现更复杂的用途，您可以通过 Iterator.initializer操作使用不同的数据集重新初始化和参数化迭代器，这样一来，您就可以在同一个程序中对训练和验证数据进行多次迭代（举例而言）。 接下来是模型部分了。为了简化写法，直接采用了TensorFlow中的layers模块： 12345678910111213141516# input Layer# x.shape = [-1, 60, 160, 3]x, y_label = iterator.get_next()keep_prob = tf.placeholder(tf.float32, [])y = tf.cast(x, tf.float32)# 3 CNN layersfor _ in range(3): y = tf.layers.conv2d(y, filters=32, kernel_size=3, padding='same', activation=tf.nn.relu) y = tf.layers.max_pooling2d(y, pool_size=1, strides=2, padding='same') # y = tf.layers.dropout(y, rate=keep_prob) # 2 dense layersy = tf.layers.flatten(y)y = tf.layers.dense(y, 1024, activation=tf.nn.relu)y = tf.layers.dropout(y, rate=keep_prob)y = tf.layers.dense(y, VOCAB_LENGTH) 这里我们的卷积核（patch）为3，padding模式为SAME，激活函数为relu。max_pooling的size为1，strides为2. 通过这样的卷积和池化层，数据的尺寸将会变成[sample_number, 32] 32是我们在tf.layers.cov2d中设置的输出channels数量(filter)。 经过全连接网络变换之后，y 的 shape 就变成了 [batch_size, n_classes]，我们的 label 是 CAPTCHA_LENGTH 个 One-Hot 向量拼合而成的，在这里我们想使用交叉熵来计算，但是交叉熵计算的时候，label 参数向量最后一维各个元素之和必须为 1，不然计算梯度的时候会出现问题。对于这个例子来说，我们现在未经处理label和logits的shape都是是[sameple_number, 1, 40]，我们想把它变成[sample_number, 4, 10]详情参见 TensorFlow 的官方文档： NOTE: While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution. If they are not, the computation of the gradient will be incorrect. reshape代码： 12y_reshape = tf.reshape(y, [-1, VOCAB_LENGTH])y_label_reshape = tf.reshape(y_label, [-1, VOCAB_LENGTH]) 接下来计算Loss和Accuracy，这里的计算交叉熵公式可以参考我另外一篇博客 1234567# losscross_entropy = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=y_reshape, labels=y_label_reshape))# accuracymax_index_predict = tf.argmax(y_reshape, axis=-1)max_index_label = tf.argmax(y_label_reshape, axis=-1)correct_predict = tf.equal(max_index_predict, max_index_label)accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32)) 训练模型123456789101112131415161718# traintrain_op = tf.train.RMSPropOptimizer(FLAGS.learning_rate).minimize(cross_entropy, global_step=global_step)for epoch in range(FLAGS.epoch_num): tf.train.global_step(sess, global_step_tensor=global_step) # train sess.run(train_initializer) for step in range(int(train_steps)): loss, acc, gstep, _ = sess.run([cross_entropy, accuracy, global_step, train_op],feed_dict=&#123;keep_prob: FLAGS.keep_prob&#125;) # print log if step % FLAGS.steps_per_print == 0: print('Global Step', gstep, 'Step', step, 'Train Loss', loss, 'Accuracy', acc) if epoch % FLAGS.epochs_per_dev == 0: # dev sess.run(dev_initializer) for step in range(int(dev_steps)): if step % FLAGS.steps_per_print == 0: print('Dev Accuracy', sess.run(accuracy, feed_dict=&#123;keep_prob: 1&#125;), 'Step', step) 在这里我们首先初始化 train_initializer，将 iterator 绑定到 Train Dataset 上，然后执行 train_op，获得 loss、acc、gstep 等结果并输出。 训练结果12345678Dev Accuracy 0.9580078 Step 0Dev Accuracy 0.9472656 Step 2Dev Accuracy 0.9501953 Step 4Dev Accuracy 0.9658203 Step 6Global Step 3243 Step 0 Train Loss 1.1920928e-06 Accuracy 1.0Global Step 3245 Step 2 Train Loss 1.5497207e-06 Accuracy 1.0Global Step 3247 Step 4 Train Loss 1.1920928e-06 Accuracy 1.0Global Step 3249 Step 6 Train Loss 1.7881392e-06 Accuracy 1.0 验证集准确率 95% 以上。 测试训练过程我们还可以每隔几个 Epoch 保存一下模型： 123# save modelif epoch % FLAGS.epochs_per_save == 0: saver.save(sess, FLAGS.checkpoint_dir, global_step=gstep) 验证模型的时候Reload模型，然后进行验证： 1234567891011# load modelckpt = tf.train.get_checkpoint_state('ckpt')if ckpt: saver.restore(sess, ckpt.model_checkpoint_path) print('Restore from', ckpt.model_checkpoint_path) sess.run(test_initializer) for step in range(int(test_steps)): if step % FLAGS.steps_per_print == 0: print('Test Accuracy', sess.run(accuracy, feed_dict=&#123;keep_prob: 1&#125;), 'Step', step)else: print('No Model Found') 验证之后其准确率基本是差不多的。]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode_3]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcode_3%2F</url>
    <content type="text"><![CDATA[[LeetCode: No.3] Given a string, find the length of the longest substring without repeating characters. 题目大意：给出一个字符串，找到最长的没有重复字符的子字符串，并返回该子字符串的长度。 Examples： Given &quot;abcabcbb&quot;, the answer is &quot;abc&quot;, which the length is 3. Given &quot;bbbbb&quot;, the answer is &quot;b&quot;, with the length of 1. Given &quot;pwwkew&quot;, the answer is &quot;wke&quot;, with the length of 3. Note that the answer must be a substring, &quot;pwke&quot; is a subsequence and not a substring. 解法一粗暴的想法是利用循环嵌套对所有情况进行遍历。大体的思路是：第一层循环从字符串的最左侧到左右侧第二个，然后第二层循环从第一层紧跟着的一个到最后的字符串，之后比较长度得到最大长度的子字符串 123456789101112131415161718192021def lengthOfLongestSubstring(self, s): """ :type s: str :rtype: int """ max_len = 0 #用这个值记录我们要返回的最长子字符串长度 #当原字符串长度为0或1的特殊情况 if (len(s) == 1 or len(s) == 0): max_len = len(s) #开始遍历每一个子字符串，并进行长度比较，得到最长的那个 for i in range(0,len(s)-1): for j in range(i+1, len(s)): if s[j] in s[i:j]: if j-i &gt; max_len: max_len = j - i break elif j == len(s) - 1: #当j是最后一个字符时，需要加上一个单位 if max_len &lt; j - i + 1: max_len = j - i + 1 return max_len 这种解法虽然可以通过，但是效率很低，时间会很长 解法二1234567891011121314151617181920def lengthOfLongestSubstring(self, s): """ :type s: str :rtype: int """ #创建一个空字典，其存放的形式是“单字符:出现位置的索引” indexDict = &#123;&#125; #存放记录最大长度和当前循环下的长度 maxLength = currMax = 0 for i in range(len(s)): #这里是当s[i]没有在之前出现过，则当前长度currMax自动加一 #当出现了重复字符，则比较当前找到的子字符串长度和历史最大长度 #重点是这里i - indexDict[s[i]] - 1 的含义；代码后举例具体讲解 if s[i] in indexDict and i - indexDict[s[i]] - 1 &lt;= currMax: if maxLength &lt; currMax: maxLength = currMax currMax = i - indexDict[s[i]] - 1 currMax = currMax + 1 indexDict[s[i]] = i #这一步也非常关键，可以更新重复字符的位置 return maxLength if currMax &lt; maxLength else currMax 接下来举例说明下为什么【i - indexDict[s[i]] - 1】代表了当前找到子字符串的长度。 比如字符串’abcdadd’，代码运行过程中一直迭代到i=3【对应字符d】时，都不满足s[i] in indexDict ,不执行条件语句，而是currMax依次加一，并且将字符信息以{s[i]:i}的形式存放在字典中。当继续迭代i=4时，进入条件语句，这里主要解释【i - indexDict[s[i]] - 1】，检测到了重复字符’a’，之前该字符出现位置为i=0处即【indexDict[s[i]] =0】这时候当前检测到的无重复字符子串为’abcd’，长度为【4-indexDict[s[i]] -1 = 3】。其他同此例。]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
</search>
